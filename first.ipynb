{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09701ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:49:16) [MSC v.1929 64 bit (AMD64)]\n",
      "Python executable: c:\\Users\\radov\\.conda\\envs\\waymo\\python.exe\n",
      "FOUND waymo_open_dataset AT local src: c:\\Users\\radov\\dev\\waymo-open-dataset\\src\\waymo_open_dataset\n",
      "Protobuf version: 3.20.3\n",
      "CORRECT protobuf VERSION!\n",
      "NumPy version: 1.23.5\n",
      "TensorFlow version: 2.15.0\n",
      "BASIC IMPORTS SUCCESSFUL.\n",
      "dataset_pb2 imported\n",
      "scenario_pb2 imported\n",
      "womd_camera_utils imported\n",
      "Additional utils imported\n",
      "ALL WAYMO IMPORTS SUCCESSFUL!\n",
      "MAPPINGS DEFINED.\n",
      "\n",
      "SETUP COMPLETE!\n",
      "If you see any errors above, restart the kernel and run this cell again.\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE SETUP:\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "src_path = os.path.join(os.getcwd(), 'src')\n",
    "src_path_abs = os.path.abspath(src_path)\n",
    "\n",
    "waymo_module_path = None\n",
    "local_src = os.path.abspath(os.path.join(os.getcwd(), 'src', 'waymo_open_dataset'))\n",
    "if os.path.exists(local_src):\n",
    "    waymo_module_path = local_src\n",
    "    src_dir = os.path.abspath(os.path.join(os.getcwd(), 'src'))\n",
    "    if src_dir not in sys.path:\n",
    "        sys.path.insert(0, src_dir)   # ensure imports from src work\n",
    "    print(f\"FOUND waymo_open_dataset AT local src: {waymo_module_path}\")\n",
    "else:\n",
    "    # 2) search existing sys.path entries (original behavior)\n",
    "    for path in sys.path:\n",
    "        potential_path = os.path.join(path, 'waymo_open_dataset')\n",
    "        if os.path.exists(potential_path):\n",
    "            waymo_module_path = potential_path\n",
    "            print(f\"FOUND waymo_open_dataset IN sys.path AT: {waymo_module_path}.\")\n",
    "            break\n",
    "if not waymo_module_path:\n",
    "    print(\"\\twaymo_open_dataset DIRECTORY NOT FOUND IN ANY sys.path LOCATION.\")\n",
    "\n",
    "\n",
    "try:    # Check protobuf version\n",
    "    import google.protobuf\n",
    "    protobuf_version = google.protobuf.__version__\n",
    "    print(f\"Protobuf version: {protobuf_version}\")\n",
    "    \n",
    "    if protobuf_version.startswith('3.20'):\n",
    "        print(\"CORRECT protobuf VERSION!\")\n",
    "    else:\n",
    "        print(f\"\\tWrong protobuf version ({protobuf_version}), need 3.20.3\")\n",
    "        print(\"Run this in terminal: conda activate waymo; pip install protobuf==3.20.3 --force-reinstall\")\n",
    "except Exception as e:\n",
    "    print(f\"\\tProtobuf ERROR: {e}\")\n",
    "\n",
    "\n",
    "try:    # Test basic imports\n",
    "    print(f\"NumPy version: {np.__version__}\")\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "    print(\"BASIC IMPORTS SUCCESSFUL.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\tBasic imports FAILED: {e}\")\n",
    "\n",
    "\n",
    "try:    # Import Waymo modules\n",
    "    from waymo_open_dataset import dataset_pb2\n",
    "    print(\"dataset_pb2 imported\")\n",
    "    \n",
    "    from waymo_open_dataset.protos import scenario_pb2\n",
    "    print(\"scenario_pb2 imported\")\n",
    "    \n",
    "    from waymo_open_dataset.utils import womd_camera_utils\n",
    "    print(\"womd_camera_utils imported\")\n",
    "    \n",
    "    # Import additional utility modules for data processing\n",
    "    from waymo_open_dataset.utils import range_image_utils\n",
    "    from waymo_open_dataset.utils import transform_utils\n",
    "    from waymo_open_dataset.utils import frame_utils\n",
    "    print(\"Additional utils imported\")\n",
    "    \n",
    "    print(\"ALL WAYMO IMPORTS SUCCESSFUL!\")\n",
    "except ImportError as e:\n",
    "    print(f\"\\tWaymo import FAILED: {e}\")\n",
    "    print(\"\\nSOLUTIONS:\")\n",
    "    print(\"1. Make sure you're in the correct directory (waymo-open-dataset/tutorial)\")\n",
    "    print(\"In /src/waymo_open_dataset you should have libraries (like math, metrics, protos, utils), __pycache__, bazel etc.\")\n",
    "    print(\"IF NOT: clone the repo: https://github.com/waymo-research/waymo-open-dataset.git\")\n",
    "    print(\"2. Compile proto files first:\")\n",
    "    print(\"   - Change to src directory: os.chdir('../src')\")\n",
    "    print(\"   - Run: subprocess.run(['python', '-m', 'grpc_tools.protoc', '--python_out=.', '--proto_path=.'] + glob.glob('waymo_open_dataset/**/*.proto', recursive=True))\")\n",
    "    print(\"3. Or run this compilation now:\")\n",
    "    try:    # Try to compile proto files automatically\n",
    "        import subprocess\n",
    "        import glob\n",
    "        current_dir = os.getcwd() # Change to src directory\n",
    "        src_dir = None\n",
    "        for potential_src in [os.path.join(current_dir, '..', 'src'),   # Find src directory\n",
    "                             os.path.join(current_dir, 'src'),\n",
    "                             r'c:\\Users\\radov\\dev\\waymo-open-dataset\\src']:\n",
    "            if os.path.exists(potential_src):\n",
    "                src_dir = potential_src\n",
    "                break\n",
    "        if src_dir:\n",
    "            print(f\"   Found src directory: {src_dir}\")\n",
    "            os.chdir(src_dir)\n",
    "            # Get proto files\n",
    "            proto_files = glob.glob('waymo_open_dataset/**/*.proto', recursive=True)\n",
    "            print(f\"   Found {len(proto_files)} proto files\")\n",
    "            if proto_files:\n",
    "                # Compile proto files\n",
    "                cmd = ['python', '-m', 'grpc_tools.protoc', '--python_out=.', '--proto_path=.'] + proto_files\n",
    "                result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "                \n",
    "                if result.returncode == 0:\n",
    "                    print(\"   Proto FILES COMPILED SUCCESSFULLY!\")\n",
    "                    os.chdir(current_dir)  # Return to original directory\n",
    "                    print(\"\\tPlease restart the kernel and run this cell again\")\n",
    "                else:\n",
    "                    print(f\"\\tProto compilation FAILED: {result.stderr}\")\n",
    "                    os.chdir(current_dir)\n",
    "            else:\n",
    "                print(\"\\tNo proto files found\")\n",
    "                os.chdir(current_dir)\n",
    "        else:\n",
    "            print(\"\\tCould not find src directory\")\n",
    "    except Exception as compile_error:\n",
    "        print(f\"\\tAuto-compilation FAILED: {compile_error}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\tUnexpected ERROR: {e}\")\n",
    "\n",
    "camera_names = {1: 'FRONT', 2: 'FRONT_LEFT', 3: 'FRONT_RIGHT', 4: 'SIDE_LEFT', 5: 'SIDE_RIGHT'}\n",
    "laser_names = {1: 'TOP', 2: 'FRONT', 3: 'SIDE_LEFT', 4: 'SIDE_RIGHT', 5: 'REAR'}\n",
    "label_types = {1: 'Vehicle', 2: 'Pedestrian', 3: 'Sign', 4: 'Cyclist'}\n",
    "print(\"MAPPINGS DEFINED.\")\n",
    "\n",
    "print(f\"\\nSETUP COMPLETE!\")\n",
    "print(f\"If you see any errors above, restart the kernel and run this cell again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ece0880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING FILES:\n",
    "training_files = []\n",
    "\n",
    "try:\n",
    "    for filename in os.listdir(r\".\\data\\training\"):\n",
    "        if filename != '.gitkeep':\n",
    "            filepath = os.path.join(r\".\\data\\training\", filename)\n",
    "            if os.path.isfile(filepath):\n",
    "                training_files.append(filepath)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# STRUCTURE OF THE DATA: past trajectory (10 timesteps), current state (1 timestep) and future trajectory (80 timesteps),\n",
    "#                        max 128 agents per scenario, max 20000 road graph points and max 16 traffic lights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1abc9c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for parsing:\n",
    "def parse_tf_example(example_proto):\n",
    "        \"\"\"Parse a tf.Example proto with minimal required agent features first.\"\"\"\n",
    "        \n",
    "        feature_description = {\n",
    "            'scenario/id': tf.io.FixedLenFeature([], tf.string),\n",
    "            # Agent identification\n",
    "            'state/id': tf.io.FixedLenFeature([128], tf.float32),\n",
    "            'state/type': tf.io.FixedLenFeature([128], tf.float32),\n",
    "            'state/is_sdc': tf.io.FixedLenFeature([128], tf.int64),\n",
    "            'state/tracks_to_predict': tf.io.FixedLenFeature([128], tf.int64),\n",
    "            # Current state positions\n",
    "            'state/current/x': tf.io.FixedLenFeature([128], tf.float32),\n",
    "            'state/current/y': tf.io.FixedLenFeature([128], tf.float32),\n",
    "            'state/current/velocity_x': tf.io.FixedLenFeature([128], tf.float32),\n",
    "            'state/current/velocity_y': tf.io.FixedLenFeature([128], tf.float32),\n",
    "            # Past trajectory\n",
    "            'state/past/x': tf.io.FixedLenFeature([128, 10], tf.float32),\n",
    "            'state/past/y': tf.io.FixedLenFeature([128, 10], tf.float32),\n",
    "            'state/past/velocity_x': tf.io.FixedLenFeature([128, 10], tf.float32),\n",
    "            'state/past/velocity_y': tf.io.FixedLenFeature([128, 10], tf.float32),\n",
    "            # Future trajectory\n",
    "            'state/future/x': tf.io.FixedLenFeature([128, 80], tf.float32),\n",
    "            'state/future/y': tf.io.FixedLenFeature([128, 80], tf.float32),\n",
    "            'state/future/velocity_x': tf.io.FixedLenFeature([128, 80], tf.float32),\n",
    "            'state/future/velocity_y': tf.io.FixedLenFeature([128, 80], tf.float32),\n",
    "        }\n",
    "        \n",
    "        optional_features = {\n",
    "            # Bounding box info\n",
    "            'state/current/bbox_yaw': tf.io.FixedLenFeature([128], tf.float32),\n",
    "            'state/current/height': tf.io.FixedLenFeature([128], tf.float32),\n",
    "            'state/current/length': tf.io.FixedLenFeature([128], tf.float32),\n",
    "            'state/current/width': tf.io.FixedLenFeature([128], tf.float32),\n",
    "            'state/current/z': tf.io.FixedLenFeature([128], tf.float32),\n",
    "            'state/current/vel_yaw': tf.io.FixedLenFeature([128], tf.float32),\n",
    "        }\n",
    "        try:    # Add optional features if they don't cause errors\n",
    "            feature_description.update(optional_features)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "def add_examples_to_array(array, dataset, num=None):\n",
    "    if num == None:\n",
    "        for raw_record in dataset:\n",
    "            try:\n",
    "                parsed_example = parse_tf_example(raw_record)\n",
    "                array.append(parsed_example)\n",
    "            except Exception as e:\n",
    "                print(f\"   Error parsing example ({e})\")\n",
    "                break\n",
    "    else:\n",
    "        for raw_record in dataset.take(num):\n",
    "            try:\n",
    "                parsed_example = parse_tf_example(raw_record)\n",
    "                array.append(parsed_example)\n",
    "            except Exception as e:\n",
    "                print(f\"   Error parsing example ({e})\")\n",
    "                break\n",
    "\n",
    "def agent_type_breakdown(agent_types, valid_agents):\n",
    "    type_names = {1: 'Vehicle', 2: 'Pedestrian', 3: 'Cyclist', 4: 'Other'}\n",
    "    type_counts = {}\n",
    "    for agent_type in agent_types[:valid_agents]:\n",
    "        type_key = int(agent_type)\n",
    "        type_name = type_names.get(type_key, f'Type_{type_key}')\n",
    "        type_counts[type_name] = type_counts.get(type_name, 0) + 1\n",
    "    a = {}\n",
    "    for type_name, count in type_counts.items():\n",
    "        a[type_name] = count\n",
    "    return a\n",
    "\n",
    "def find_SDC(is_SDC, current_state):\n",
    "    sdc_idx = np.where(is_SDC == 1)[0]\n",
    "    if len(sdc_idx) > 0:\n",
    "        sdc_idx = sdc_idx[0]\n",
    "        sdc_speed = np.sqrt(current_state[2][sdc_idx]**2 + current_state[3][sdc_idx]**2)\n",
    "        return str(f\"   SDC position: ({current_state[0][sdc_idx]:.2f}, {current_state[1][sdc_idx]:.2f})\\n \\\n",
    "  SDC speed: {sdc_speed:.2f} m/s ({sdc_speed * 3.6:.1f} km/h)\")\n",
    "\n",
    "def analyze_roadgraph(example):\n",
    "    try:\n",
    "        if 'roadgraph_samples/valid' in example:\n",
    "            roadgraph_valid = example['roadgraph_samples/valid'].numpy()\n",
    "            valid_road_points = np.sum(roadgraph_valid == 1)\n",
    "            return str(f\"   Road graph points: {valid_road_points}\")\n",
    "        else:\n",
    "            return str(f\"   Road graph: Not available in this file\")\n",
    "    except:\n",
    "        return str(f\"   Road graph: Not parsed (optional feature)\")\n",
    "    \n",
    "def analyze_example(example, prinT=True):\n",
    "    # data:\n",
    "    scenario_ID = example['scenario/id'].numpy().decode('utf-8')\n",
    "    agent_IDs = example['state/id'].numpy()\n",
    "    agent_types = example['state/type'].numpy()\n",
    "\n",
    "    is_SDC = example['state/is_sdc'].numpy()    # SDC = Self-Driving Car\n",
    "    tracks_to_predict = example['state/tracks_to_predict'].numpy()\n",
    "\n",
    "    # current SDC state:\n",
    "    current_x = example['state/current/x'].numpy()\n",
    "    current_y = example['state/current/y'].numpy()\n",
    "    current_vel_x = example['state/current/velocity_x'].numpy()\n",
    "    current_vel_y = example['state/current/velocity_y'].numpy()\n",
    "    current_state = [current_x, current_y, current_vel_x, current_vel_y]\n",
    "    #find_SDC(is_SDC, current_state)\n",
    "\n",
    "    # stats:\n",
    "    valid_agents = np.sum(agent_IDs != 0.0)\n",
    "    SDC_count = np.sum(is_SDC == 1)\n",
    "    predict_count = np.sum(tracks_to_predict == 1)\n",
    "\n",
    "    if prinT:\n",
    "        print(f\"The example:\\n \\\n",
    " - Stats: \\n \\\n",
    "    - valid_agents: {valid_agents}\\n \\\n",
    "    - SDC_count: {SDC_count}\\n \\\n",
    "    - predict_count: {predict_count}\\n \\\n",
    "    - SDC_state: {find_SDC(is_SDC, current_state)}\\n \\\n",
    " - Data: \\n \\\n",
    "    - scenario_ID: {scenario_ID}\\n \\\n",
    "    - agent_IDs: {agent_IDs}\\n \\\n",
    "    - agent_types: {agent_type_breakdown(agent_types, valid_agents)}\\n \\\n",
    "    - is_SDC: {is_SDC}\\n \\\n",
    "    - tracks_to_predict: {tracks_to_predict}\\n \\\n",
    " - Road graph: \\n \\\n",
    "    - {analyze_roadgraph(example)}\\n \\\n",
    "\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8665a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 477 training_examples to dataset array of training_file with ID = 0 (from .\\data\\training\\uncompressed_tf_example_training_training_tfexample.tfrecord-00000-of-01000)\n",
      "Added 466 training_examples to dataset array of training_file with ID = 1 (from .\\data\\training\\uncompressed_tf_example_training_training_tfexample.tfrecord-00001-of-01000)\n",
      "Added 477 training_examples to dataset array of training_file with ID = 2 (from .\\data\\training\\uncompressed_tf_example_training_training_tfexample.tfrecord-00002-of-01000)\n"
     ]
    }
   ],
   "source": [
    "# TRAINING DATASET:\n",
    "training_dataset = {}   # training_file_ID: [training_examples]\n",
    "\n",
    "try:\n",
    "    for training_file in enumerate(training_files):\n",
    "        training_file_index = training_file[0]\n",
    "        training_file_path = training_file[1]\n",
    "        #print(training_file_path)\n",
    "\n",
    "        dataset_record = tf.data.TFRecordDataset(training_file_path, compression_type='')\n",
    "\n",
    "        training_dataset[training_file_index] = []\n",
    "        add_examples_to_array(training_dataset[training_file_index], dataset_record)\n",
    "        print(f\"Added {len(training_dataset[training_file_index])} training_examples to dataset array of training_file with ID = {training_file_index} (from {training_file_path})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing training dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5111f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The example:\n",
      "  - Stats: \n",
      "     - valid_agents: 128\n",
      "     - SDC_count: 1\n",
      "     - predict_count: 5\n",
      "     - SDC_state:    SDC position: (6267.20, 124.35)\n",
      "   SDC speed: 0.00 m/s (0.0 km/h)\n",
      "  - Data: \n",
      "     - scenario_ID: 4773a3ef01ddc58c\n",
      "     - agent_IDs: [1773. 1778. 1805. 2651. 2656. 2846. 2650. 1763. 2649. 2653. 2660. 1770.\n",
      " 2658. 2712. 2701. 2648. 2655. 1764. 1797. 1765. 2719. 2671. 1762. 1782.\n",
      " 1775. 1767. 1771. 1766. 1768. 1810. 1760. 1774. 2696. 1800. 1787. 2727.\n",
      " 2679. 1772. 2657. 1784. 1815. 1776. 1842. 1777. 1761. 1832. 1791. 2697.\n",
      " 1841. 2664. 1798. 1781. 1806. 1779. 1783. 1901. 1847. 1799. 1789. 1786.\n",
      " 1835. 1780. 1788. 1830. 2654. 1820. 1802. 1890. 1837. 1873. 1833. 1828.\n",
      " 1881. 1862. 2691. 1825. 1803. 1883. 1822. 1816. 1907. 1856. 1904. 1796.\n",
      " 1792. 1884. 1795. 1910. 1794. 1821. 1903. 2662. 1902. 1812. 1793. 1839.\n",
      " 1769. 1814. 1823. 1785. 1818. 1790. 1811. 1838. 1857. 1843. 1886. 1817.\n",
      " 1824. 1804. 1819. 1840. 1870. 1869. 1826. 1829. 1852. 1859. 1849. 1831.\n",
      " 1845. 1844. 2667. 1846. 1891. 1895. 1867. 1836.]\n",
      "     - agent_types: {'Vehicle': 105, 'Pedestrian': 23}\n",
      "     - is_SDC: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "     - tracks_to_predict: [1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  - Road graph: \n",
      "     -    Road graph: Not available in this file\n",
      " \n"
     ]
    }
   ],
   "source": [
    "analyze_example(training_dataset[0][0])     # training_dataset[fileID][example]\n",
    "#analyze_example(training_dataset[0][1])\n",
    "#analyze_example(training_dataset[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffbf84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (3.9.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# VISUALIZATION OF THE SCENE (2D scenes for trajectory prediction):\n",
    "%pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "\n",
    "def create_figure_and_axes(size_pixels):\n",
    "  \"\"\"Initializes a unique figure and axes for plotting.\"\"\"\n",
    "  fig, ax = plt.subplots(1, 1, num=uuid.uuid4())\n",
    "  dpi = 100\n",
    "  size_inches = size_pixels / dpi\n",
    "  fig.set_size_inches([size_inches, size_inches])\n",
    "  fig.set_dpi(dpi)\n",
    "  fig.set_facecolor('white')\n",
    "  ax.set_facecolor('white')\n",
    "  ax.grid(False)\n",
    "  ax.get_xaxis().set_ticks([])\n",
    "  ax.get_yaxis().set_ticks([])\n",
    "  return fig, ax\n",
    "\n",
    "def get_viewport(all_states, all_states_mask):\n",
    "  \"\"\"Gets the region containing the valid data.\"\"\"\n",
    "  # Ensure there are valid states to prevent errors on empty masks\n",
    "  if not np.any(all_states_mask):\n",
    "      # Return a default viewport if no valid states exist\n",
    "      return 0, 0, 100 \n",
    "\n",
    "  valid_states = all_states[all_states_mask]\n",
    "  all_y = valid_states[..., 1]\n",
    "  all_x = valid_states[..., 0]\n",
    "\n",
    "  center_y = (np.max(all_y) + np.min(all_y)) / 2\n",
    "  center_x = (np.max(all_x) + np.min(all_x)) / 2\n",
    "\n",
    "  range_y = np.ptp(all_y) if len(all_y) > 0 else 0\n",
    "  range_x = np.ptp(all_x) if len(all_x) > 0 else 0\n",
    "\n",
    "  width = max(range_y, range_x)\n",
    "  return center_y, center_x, width\n",
    "\n",
    "def print_agent(idx, all_states, decoded_example):\n",
    "   agent_IDs = decoded_example['state/id'].numpy()\n",
    "   type_names = {1: 'Vehicle', 2: 'Pedestrian', 3: 'Cyclist', 4: 'Other'}\n",
    "   agent_type = type_names[decoded_example['state/type'].numpy()[idx]]\n",
    "   is_SDC_mask = decoded_example['state/is_sdc'].numpy() > 0\n",
    "   is_SDC = is_SDC_mask[idx]\n",
    "   print(f\"Agent #{idx} with ID {int(agent_IDs[idx])} is {'SDC' if is_SDC else ''} {agent_type}.\")\n",
    "   agent_states = all_states[idx]\n",
    "   # TODO STATES, COORDINATES, ...\n",
    "   \n",
    "   \n",
    "\n",
    "def visualize_from_example(decoded_example, size_pixels=1000):\n",
    "  \"\"\"Visualizes agent trajectories from a Waymo motion tf.train.Example.\"\"\"\n",
    "  \n",
    "  # EXTRACT THE STATES AND MAKE DATA VALIDITY MASKS:  \n",
    "  past_states = tf.stack([decoded_example['state/past/x'], decoded_example['state/past/y']], -1).numpy()  # [num_agents, num_past_steps, 2]\n",
    "  past_states_mask = past_states[..., 0] != -1.0  # Mask is True where x is not -1, indicating valid data.\n",
    "\n",
    "  current_states = tf.stack([decoded_example['state/current/x'], decoded_example['state/current/y']], -1).numpy()  \n",
    "  if current_states.ndim == 2:\n",
    "      current_states = np.expand_dims(current_states, axis=1)  # [num_agents, 1, 2] (converted from [num_agents, 2])\n",
    "  current_states_mask = current_states[..., 0] != -1.0\n",
    "\n",
    "  future_states = tf.stack([decoded_example['state/future/x'], decoded_example['state/future/y']], -1).numpy()  # [num_agents, num_future_steps, 2]\n",
    "  future_states_mask = future_states[..., 0] != -1.0\n",
    "  \n",
    "  all_states = np.concatenate([past_states, current_states, future_states], 1)  # [num_agents, num_steps, 2]\n",
    "  all_states_mask = np.concatenate([past_states_mask, current_states_mask, future_states_mask], 1)  # [num_agents, num_steps]\n",
    "\n",
    "  # GET TRACKS TO PREDICT, SET COLORS TO AGENTS AND TRACKS TO PREDICT AND MAKE FIGURE:\n",
    "  tracks_to_predict = decoded_example['state/tracks_to_predict'].numpy() > 0\n",
    "  is_SDC_mask = decoded_example['state/is_sdc'].numpy() > 0\n",
    "  # Build per-agent colors:\n",
    "    # GREEN ... SDC\n",
    "    # RED ... predicted\n",
    "    # BLUE ... other agents\n",
    "  color_list = np.where(is_SDC_mask, '#0f0', np.where(tracks_to_predict, '#d33', '#33d'))\n",
    "  color_map = color_list.reshape(1, -1)  # keep indexing as color_map[0, agent]\n",
    "  fig, ax = create_figure_and_axes(size_pixels=size_pixels)\n",
    "  ax.set_title(f'Scenario ID: {decoded_example[\"scenario/id\"].numpy().decode(\"utf-8\")}')\n",
    "\n",
    "  # --- 2. Make roadgraph plotting optional ---\n",
    "  if 'roadgraph_samples/xyz' in decoded_example:\n",
    "      roadgraph_xyz = decoded_example['roadgraph_samples/xyz'].numpy()\n",
    "      ax.scatter(roadgraph_xyz[:, 0], roadgraph_xyz[:, 1], c='grey', s=1, alpha=0.2)\n",
    "      ax.set_facecolor('white') # Keep white background if map exists\n",
    "  else:\n",
    "      # If no map data, use a dark background for better trajectory visibility\n",
    "      fig.set_facecolor('black')\n",
    "      ax.set_facecolor('black')\n",
    "  \n",
    "  \n",
    "  max_num_agents = len(decoded_example['state/future/y'])\n",
    "  agent_IDs = decoded_example['state/id'].numpy()\n",
    "  valid_agents = np.sum(agent_IDs != -1.0)\n",
    "  num_past_steps = len(decoded_example['state/past/x'][0])\n",
    "  num_future_steps = len(decoded_example['state/future/y'][0])\n",
    "  print(f\"In this scenario there are {valid_agents} out of {max_num_agents} possible agents. \\nWe have measurements about {num_past_steps} past steps, 1 current step and {num_future_steps} future steps.\")\n",
    "  print_agent(1, all_states, decoded_example)\n",
    "\n",
    "\n",
    "  # PLOT ALL AGENTS:\n",
    "  for agent in range(all_states.shape[0]):\n",
    "\n",
    "    if np.any(all_states_mask[agent]):  # Only plot if there is at least one valid point for this agent\n",
    "        \n",
    "        ax.plot(past_states[agent, past_states_mask[agent], 0],\n",
    "                past_states[agent, past_states_mask[agent], 1],\n",
    "                '-', color=color_map[0, agent], alpha=0.8, linewidth=2, zorder=15)  # Past states (solid line)\n",
    "\n",
    "        ax.plot(future_states[agent, future_states_mask[agent], 0],\n",
    "                future_states[agent, future_states_mask[agent], 1],\n",
    "                '--', color=color_map[0, agent], alpha=0.8, linewidth=2, zorder=15)  # Future states (dashed line)\n",
    "        \n",
    "        ax.scatter(current_states[agent, current_states_mask[agent], 0],\n",
    "                   current_states[agent, current_states_mask[agent], 1],\n",
    "                   marker='o', facecolors='none', edgecolors=color_map[0, agent], linewidths=3, s=80, zorder=20)  # Current state (circle)\n",
    "\n",
    "        if is_SDC_mask[agent] or tracks_to_predict[agent]:\n",
    "            # pick a position for the label: prefer current state, else first valid point\n",
    "            if np.any(current_states_mask[agent]):\n",
    "                label_pos = current_states[agent, current_states_mask[agent]][0]\n",
    "            else:\n",
    "                valid_indices = np.where(all_states_mask[agent])[0]\n",
    "                label_pos = all_states[agent, valid_indices[0]]\n",
    "\n",
    "            # Use the per-agent ID (fallback to loop index if missing)\n",
    "            if agent_IDs[agent] != -1.0:\n",
    "                type_names = {1: 'Vehicle', 2: 'Pedestrian', 3: 'Cyclist', 4: 'Other'}\n",
    "                agent_type = type_names[decoded_example['state/type'].numpy()[agent]]\n",
    "                print(agent_type)\n",
    "                label_text = agent_type + '\\n' + str(int(agent_IDs[agent]))\n",
    "            else:\n",
    "                label_text = str('')\n",
    "\n",
    "            ax.annotate(\n",
    "                label_text,\n",
    "                xy=(label_pos[0], label_pos[1]),\n",
    "                xytext=(8, 8),                # offset (x, y) in points\n",
    "                textcoords='offset points',\n",
    "                color=color_map[0, agent],\n",
    "                fontsize=6,\n",
    "                ha='left',\n",
    "                va='bottom',\n",
    "                fontweight='bold',\n",
    "                bbox=dict(facecolor='black', alpha=0.9, edgecolor='none', pad=0.8),\n",
    "                zorder=25,\n",
    "            )\n",
    "\n",
    "  # SET GRAPH:\n",
    "  center_y, center_x, width = get_viewport(all_states, all_states_mask)\n",
    "  size = max(50, width * 1.5) # Ensure a minimum size for the viewport\n",
    "  ax.axis([\n",
    "      -size / 2 + center_x, size / 2 + center_x, -size / 2 + center_y,\n",
    "      size / 2 + center_y\n",
    "  ])\n",
    "  ax.set_aspect('equal')\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc0d0b57",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visualize_from_example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mvisualize_from_example\u001b[49m(training_dataset[\u001b[38;5;241m0\u001b[39m][i])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'visualize_from_example' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    visualize_from_example(training_dataset[0][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waymo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
