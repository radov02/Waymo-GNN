{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774412a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version:  2.9.0+cu128\n",
      "Torch CUDA Available:  True\n",
      "Torch CUDA Device Name:  NVIDIA GeForce GTX 1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GeForce GTX 1070 which is of cuda capability 6.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:304: UserWarning: \n",
      "    Please install PyTorch with a following CUDA\n",
      "    configurations:  12.6 following instructions at\n",
      "    https://pytorch.org/get-started/locally/\n",
      "    \n",
      "  warnings.warn(matched_cuda_warn.format(matched_arches))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:326: UserWarning: \n",
      "NVIDIA GeForce GTX 1070 with CUDA capability sm_61 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.\n",
      "If you want to use the NVIDIA GeForce GTX 1070 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch Version: \", torch.__version__)\n",
    "print(\"Torch CUDA Available: \", torch.cuda.is_available())\n",
    "print(\"Torch CUDA Device Name: \", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047be7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\radov\\.conda\\envs\\waymo\\python.exe\n",
      "Site-packages: c:\\Users\\radov\\.conda\\envs\\Lib\\site-packages\n",
      "\n",
      "Removing 0 torch-related directories...\n",
      "\n",
      "Installing fresh PyTorch...\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch==2.4.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (2.4.0+cu118)\n",
      "Requirement already satisfied: torchvision==0.19.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (0.19.0+cu118)\n",
      "Requirement already satisfied: torchaudio==2.4.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (2.4.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch==2.4.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch==2.4.0) (4.15.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch==2.4.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch==2.4.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch==2.4.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch==2.4.0) (2025.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torchvision==0.19.0) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torchvision==0.19.0) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from jinja2->torch==2.4.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch==2.4.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (2.4.0+cu118)\n",
      "Requirement already satisfied: torchvision==0.19.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (0.19.0+cu118)\n",
      "Requirement already satisfied: torchaudio==2.4.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (2.4.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch==2.4.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch==2.4.0) (4.15.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch==2.4.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch==2.4.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch==2.4.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch==2.4.0) (2025.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torchvision==0.19.0) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torchvision==0.19.0) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from jinja2->torch==2.4.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu118.html\n",
      "Requirement already satisfied: torch-scatter in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (2.1.2+pt24cu118)\n",
      "Requirement already satisfied: torch-sparse in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (0.6.18+pt24cu118)\n",
      "Requirement already satisfied: scipy in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-sparse) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from scipy->torch-sparse) (1.24.3)\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu118.html\n",
      "Requirement already satisfied: torch-scatter in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (2.1.2+pt24cu118)\n",
      "Requirement already satisfied: torch-sparse in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (0.6.18+pt24cu118)\n",
      "Requirement already satisfied: scipy in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-sparse) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from scipy->torch-sparse) (1.24.3)\n",
      "Requirement already satisfied: torch-geometric in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: ogb in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (1.3.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (3.12.15)\n",
      "Requirement already satisfied: fsspec in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (2025.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from ogb) (2.4.0+cu118)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from ogb) (1.6.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from ogb) (2.3.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from ogb) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from ogb) (2.5.0)\n",
      "Requirement already satisfied: outdated>=0.2.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from ogb) (0.2.2)\n",
      "Requirement already satisfied: setuptools>=44 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from outdated>=0.2.0->ogb) (80.9.0)\n",
      "Requirement already satisfied: littleutils in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from outdated>=0.2.0->ogb) (0.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from pandas>=0.24.0->ogb) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from scikit-learn>=0.20.0->ogb) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from scikit-learn>=0.20.0->ogb) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from scikit-learn>=0.20.0->ogb) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch>=1.6.0->ogb) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch>=1.6.0->ogb) (4.15.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch>=1.6.0->ogb) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch>=1.6.0->ogb) (3.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (1.18.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch-geometric) (3.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from jinja2->torch-geometric) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from requests->torch-geometric) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
      "\n",
      "============================================================\n",
      "INSTALLATION COMPLETE!\n",
      "NEXT STEP: Click 'Restart' button in notebook toolbar\n",
      "============================================================\n",
      "Requirement already satisfied: torch-geometric in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: ogb in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (1.3.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (3.12.15)\n",
      "Requirement already satisfied: fsspec in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (2025.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from ogb) (2.4.0+cu118)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from ogb) (1.6.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from ogb) (2.3.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from ogb) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from ogb) (2.5.0)\n",
      "Requirement already satisfied: outdated>=0.2.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from ogb) (0.2.2)\n",
      "Requirement already satisfied: setuptools>=44 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from outdated>=0.2.0->ogb) (80.9.0)\n",
      "Requirement already satisfied: littleutils in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from outdated>=0.2.0->ogb) (0.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from pandas>=0.24.0->ogb) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from scikit-learn>=0.20.0->ogb) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from scikit-learn>=0.20.0->ogb) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from scikit-learn>=0.20.0->ogb) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch>=1.6.0->ogb) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch>=1.6.0->ogb) (4.15.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch>=1.6.0->ogb) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from torch>=1.6.0->ogb) (3.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from aiohttp->torch-geometric) (1.18.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch-geometric) (3.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from jinja2->torch-geometric) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from requests->torch-geometric) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\radov\\.conda\\envs\\waymo\\lib\\site-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
      "\n",
      "============================================================\n",
      "INSTALLATION COMPLETE!\n",
      "NEXT STEP: Click 'Restart' button in notebook toolbar\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Get site-packages directory\n",
    "site_packages = Path(sys.executable).parent.parent / \"Lib\" / \"site-packages\"\n",
    "print(f\"Site-packages: {site_packages}\")\n",
    "\n",
    "# Remove all torch-related directories manually\n",
    "torch_dirs = list(site_packages.glob(\"torch*\"))\n",
    "print(f\"\\nRemoving {len(torch_dirs)} torch-related directories...\")\n",
    "for d in torch_dirs:\n",
    "    try:\n",
    "        if d.is_dir():\n",
    "            shutil.rmtree(d, ignore_errors=True)\n",
    "            print(f\"  Removed: {d.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error removing {d.name}: {e}\")\n",
    "\n",
    "print(\"\\nInstalling fresh PyTorch...\")\n",
    "# Install PyTorch 2.4.0 with CUDA 11.8 support\n",
    "!{sys.executable} -m pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install PyG dependencies compatible with PyTorch 2.4.0\n",
    "!{sys.executable} -m pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cu118.html\n",
    "\n",
    "# Install PyG and OGB\n",
    "!{sys.executable} -m pip install torch-geometric ogb\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INSTALLATION COMPLETE!\")\n",
    "print(\"NEXT STEP: Click 'Restart' button in notebook toolbar\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a9adb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES(600)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "root = './enzymes'\n",
    "name = 'ENZYMES'\n",
    "\n",
    "# The ENZYMES dataset\n",
    "pyg_dataset= TUDataset(root, name)\n",
    "\n",
    "# You will find that there are 600 graphs in this dataset\n",
    "print(pyg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa5f05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling conflicting packages...\n",
      "\n",
      "Installing compatible scientific Python stack...\n",
      "\n",
      "Installing compatible scientific Python stack...\n",
      "\n",
      "============================================================\n",
      "Installation complete!\n",
      "RESTART KERNEL and verify\n",
      "============================================================\n",
      "\n",
      "PyTorch version: 2.4.0+cu118\n",
      "NumPy version: 1.26.4\n",
      "CUDA available: False\n",
      "\n",
      "============================================================\n",
      "Installation complete!\n",
      "RESTART KERNEL and verify\n",
      "============================================================\n",
      "\n",
      "PyTorch version: 2.4.0+cu118\n",
      "NumPy version: 1.26.4\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Fix the entire scientific Python stack\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Uninstall problematic packages\n",
    "print(\"Uninstalling conflicting packages...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"numpy\", \"pandas\", \"scikit-learn\", \"scipy\"], check=False)\n",
    "\n",
    "# Install compatible versions\n",
    "print(\"\\nInstalling compatible scientific Python stack...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"numpy==1.24.3\"], check=True)\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\", \"scikit-learn\", \"scipy\"], check=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Installation complete!\")\n",
    "print(\"RESTART KERNEL and verify\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Now verify\n",
    "import torch\n",
    "import numpy as np\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce66e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES dataset has 6 classes\n",
      "ENZYMES dataset has 3 features\n"
     ]
    }
   ],
   "source": [
    "def get_num_classes(pyg_dataset):\n",
    "  # TODO: Implement a function that takes a PyG dataset object\n",
    "  # and returns the number of classes for that dataset.\n",
    "\n",
    "  num_classes = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 line of code)\n",
    "  ## Note\n",
    "  ## 1. Colab autocomplete functionality might be useful.\n",
    "  num_classes = pyg_dataset.num_classes\n",
    "  #########################################\n",
    "\n",
    "  return num_classes\n",
    "\n",
    "def get_num_features(pyg_dataset):\n",
    "  # TODO: Implement a function that takes a PyG dataset object\n",
    "  # and returns the number of features for that dataset.\n",
    "\n",
    "  num_features = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 line of code)\n",
    "  ## Note\n",
    "  ## 1. Colab autocomplete functionality might be useful.\n",
    "  num_features = pyg_dataset.num_features\n",
    "  #########################################\n",
    "\n",
    "  return num_features\n",
    "\n",
    "num_classes = get_num_classes(pyg_dataset)\n",
    "num_features = get_num_features(pyg_dataset)\n",
    "print(\"{} dataset has {} classes\".format(name, num_classes))\n",
    "print(\"{} dataset has {} features\".format(name, num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf558441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
      "Graph with index 100 has label tensor([4])\n"
     ]
    }
   ],
   "source": [
    "def get_graph_class(pyg_dataset, idx):\n",
    "  # TODO: Implement a function that takes a PyG dataset object,\n",
    "  # an index of a graph within the dataset, and returns the class/label\n",
    "  # of the graph (as an integer).\n",
    "\n",
    "  label = -1\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 line of code)\n",
    "  #print(pyg_dataset.data.y)\n",
    "  graph = pyg_dataset[100]\n",
    "  label = graph.y\n",
    "  #########################################\n",
    "\n",
    "  return label\n",
    "\n",
    "# Here pyg_dataset is a dataset for graph classification\n",
    "graph_0 = pyg_dataset[0]\n",
    "print(graph_0)\n",
    "idx = 100\n",
    "label = get_graph_class(pyg_dataset, idx)\n",
    "print('Graph with index {} has label {}'.format(idx, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d042df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with index 200 has 53 edges\n"
     ]
    }
   ],
   "source": [
    "def get_graph_num_edges(pyg_dataset, idx):\n",
    "  # TODO: Implement a function that takes a PyG dataset object,\n",
    "  # the index of a graph in the dataset, and returns the number of\n",
    "  # edges in the graph (as an integer). You should not count an edge\n",
    "  # twice if the graph is undirected. For example, in an undirected\n",
    "  # graph G, if two nodes v and u are connected by an edge, this edge\n",
    "  # should only be counted once.\n",
    "\n",
    "  num_edges = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## Note:\n",
    "  ## 1. You can't return the data.num_edges directly\n",
    "  ## 2. We assume the graph is undirected\n",
    "  ## 3. Look at the PyG dataset built in functions\n",
    "  ## (~4 lines of code)\n",
    "  #print(graph.num_edges)\n",
    "  graph = pyg_dataset[idx]\n",
    "  if not graph.is_directed():\n",
    "    num_edges = int(graph.num_edges / 2)\n",
    "  else:\n",
    "    num_edges = graph.num_edges\n",
    "\n",
    "  #########################################\n",
    "\n",
    "  return num_edges\n",
    "\n",
    "idx = 200\n",
    "num_edges = get_graph_num_edges(pyg_dataset, idx)\n",
    "print('Graph with index {} has {} edges'.format(idx, num_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ee15a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\radov\\.conda\\envs\\waymo\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "c:\\Users\\radov\\.conda\\envs\\waymo\\lib\\site-packages\\outdated\\__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "c:\\Users\\radov\\.conda\\envs\\waymo\\lib\\site-packages\\ogb\\nodeproppred\\dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n",
      "c:\\Users\\radov\\.conda\\envs\\waymo\\lib\\site-packages\\ogb\\nodeproppred\\dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ogbn-arxiv dataset has 1 graph\n",
      "Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343, nnz=1166243])\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "dataset_name = 'ogbn-arxiv'\n",
    "# Load the dataset and transform it to sparse tensor\n",
    "dataset = PygNodePropPredDataset(name=dataset_name,\n",
    "                                  transform=T.ToSparseTensor())\n",
    "print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n",
    "\n",
    "# Extract the graph\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9c4954a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph has 128 features\n"
     ]
    }
   ],
   "source": [
    "def graph_num_features(data):\n",
    "  # TODO: Implement a function that takes a PyG data object,\n",
    "  # and returns the number of features in the graph (as an integer).\n",
    "\n",
    "  num_features = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 line of code)\n",
    "  num_features = data.num_features\n",
    "\n",
    "  #########################################\n",
    "\n",
    "  return num_features\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  num_features = graph_num_features(data)\n",
    "  print('The graph has {} features'.format(num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb3ac0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "print(torch.__version__)\n",
    "\n",
    "# The PyG built-in GCNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb76e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\radov\\.conda\\envs\\waymo\\lib\\site-packages\\ogb\\nodeproppred\\dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'ogbn-arxiv'\n",
    "dataset = PygNodePropPredDataset(name=dataset_name,\n",
    "                                  transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "\n",
    "# Make the adjacency matrix to symmetric\n",
    "data.adj_t = data.adj_t.to_symmetric()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# If you use GPU, the device should be cuda\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "data = data.to(device)\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18a2098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout, return_embeds=False):\n",
    "        # TODO: Implement a function that initializes self.convs,\n",
    "        # self.bns, and self.softmax.\n",
    "\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # A list of GCNConv layers\n",
    "        self.convs = None\n",
    "\n",
    "        # A list of 1D batch normalization layers\n",
    "        self.bns = None\n",
    "\n",
    "        # The log softmax layer\n",
    "        self.softmax = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. You should use torch.nn.ModuleList for self.convs and self.bns\n",
    "        ## 2. self.convs has num_layers GCNConv layers\n",
    "        ## 3. self.bns has num_layers - 1 BatchNorm1d layers\n",
    "        ## 4. You should use torch.nn.LogSoftmax for self.softmax\n",
    "        ## 5. The parameters you can set for GCNConv include 'in_channels' and\n",
    "        ## 'out_channels'. For more information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n",
    "        ## 6. The only parameter you need to set for BatchNorm1d is 'num_features'\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
    "        ## (~10 lines of code)\n",
    "        self.convs = torch.nn.ModuleList([GCNConv(input_dim, hidden_dim)] +\n",
    "                                         [GCNConv(hidden_dim, hidden_dim) for i in range(num_layers-2)] +\n",
    "                                         [GCNConv(hidden_dim, output_dim)])\n",
    "\n",
    "        self.bns = torch.nn.ModuleList([torch.nn.BatchNorm1d(hidden_dim)\n",
    "                                       for i in range(num_layers-1)])\n",
    "\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        #########################################\n",
    "\n",
    "        # Probability of an element getting zeroed\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Skip classification layer and return node embeddings\n",
    "        self.return_embeds = return_embeds\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        # TODO: Implement a function that takes the feature tensor x and\n",
    "        # edge_index tensor adj_t and returns the output tensor as\n",
    "        # shown in the figure.\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Construct the network as shown in the figure\n",
    "        ## 2. torch.nn.functional.relu and torch.nn.functional.dropout are useful\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch.org/docs/stable/nn.functional.html\n",
    "        ## 3. Don't forget to set F.dropout training to self.training\n",
    "        ## 4. If return_embeds is True, then skip the last softmax layer\n",
    "        ## (~7 lines of code)\n",
    "\n",
    "        for i in range(len(self.convs)):\n",
    "            if i < len(self.convs) - 1:\n",
    "                x = self.convs[i](x, adj_t)\n",
    "                x = self.bns[i](x)\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            else:\n",
    "                out = self.convs[i](x, adj_t)\n",
    "\n",
    "        if not self.return_embeds:\n",
    "          out = self.softmax(out)\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10620479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer, loss_fn):\n",
    "    # TODO: Implement a function that trains the model by\n",
    "    # using the given optimizer and loss_fn.\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## Note:\n",
    "    ## 1. Zero grad the optimizer\n",
    "    ## 2. Feed the data into the model\n",
    "    ## 3. Slice the model output and label by train_idx\n",
    "    ## 4. Feed the sliced output and label to loss_fn\n",
    "    ## (~4 lines of code)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    model_output = model(data.x, data.adj_t)\n",
    "    # train_idx is indexing array that selects the outputs used for learning (loss, backprop)\n",
    "    train_idx_output = model_output[train_idx]  # mask/index the model output as suggested by train_idx\n",
    "    train_idx_label = data.y[train_idx]   # get labels for masked model outputs\n",
    "\n",
    "    #print(train_idx_label)\n",
    "    #print(train_idx_label.size())\n",
    "    #print(train_idx_label.squeeze())  # squeeze removes dimensions of size 1 by rearranging the data to fit the new dimensions (same but without dimensions of 1)\n",
    "\n",
    "    loss = loss_fn(train_idx_output, train_idx_label.squeeze())\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3338559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function here\n",
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator, save_model_results=False):\n",
    "    # TODO: Implement a function that tests the model by\n",
    "    # using the given split_idx and evaluator.\n",
    "    model.eval()\n",
    "\n",
    "    # The output of model on all data\n",
    "    out = None\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    ## Note:\n",
    "    ## 1. No index slicing here\n",
    "\n",
    "    out = model(data.x, data.adj_t)  # do forward pass\n",
    "\n",
    "    # get the model outputs and then evaluate the accuracy:\n",
    "    #########################################\n",
    "\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    if save_model_results:\n",
    "      print (\"Saving Model Predictions\")\n",
    "\n",
    "      data = {}\n",
    "      data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n",
    "\n",
    "      df = pd.DataFrame(data=data)\n",
    "      # Save locally as csv\n",
    "      df.to_csv('ogbn-arxiv_node.csv', sep=',', index=False)\n",
    "\n",
    "\n",
    "    return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6971f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cpu',\n",
       " 'num_layers': 3,\n",
       " 'hidden_dim': 256,\n",
       " 'dropout': 0.5,\n",
       " 'lr': 0.01,\n",
       " 'epochs': 100}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {\n",
    "      'device': device,\n",
    "      'num_layers': 3,\n",
    "      'hidden_dim': 256,\n",
    "      'dropout': 0.5,\n",
    "      'lr': 0.01,\n",
    "      'epochs': 100,\n",
    "  }\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "200866f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(data.num_features, args['hidden_dim'],\n",
    "              dataset.num_classes, args['num_layers'],\n",
    "              args['dropout']).to(device)\n",
    "evaluator = Evaluator(name='ogbn-arxiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d886f610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\radov\\.conda\\envs\\waymo\\lib\\site-packages\\torch_sparse\\tensor.py:574: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:55.)\n",
      "  return torch.sparse_csr_tensor(rowptr, col, value, self.sizes())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 4.3476, Train: 21.20%, Valid: 27.04% Test: 24.41%\n",
      "Epoch: 02, Loss: 2.3248, Train: 21.36%, Valid: 20.90% Test: 26.35%\n",
      "Epoch: 02, Loss: 2.3248, Train: 21.36%, Valid: 20.90% Test: 26.35%\n",
      "Epoch: 03, Loss: 1.9821, Train: 30.15%, Valid: 27.05% Test: 31.79%\n",
      "Epoch: 03, Loss: 1.9821, Train: 30.15%, Valid: 27.05% Test: 31.79%\n",
      "Epoch: 04, Loss: 1.7986, Train: 41.54%, Valid: 34.33% Test: 38.24%\n",
      "Epoch: 04, Loss: 1.7986, Train: 41.54%, Valid: 34.33% Test: 38.24%\n",
      "Epoch: 05, Loss: 1.6928, Train: 39.58%, Valid: 31.17% Test: 34.38%\n",
      "Epoch: 05, Loss: 1.6928, Train: 39.58%, Valid: 31.17% Test: 34.38%\n",
      "Epoch: 06, Loss: 1.6040, Train: 39.00%, Valid: 30.78% Test: 33.06%\n",
      "Epoch: 06, Loss: 1.6040, Train: 39.00%, Valid: 30.78% Test: 33.06%\n",
      "Epoch: 07, Loss: 1.5242, Train: 39.52%, Valid: 27.47% Test: 28.32%\n",
      "Epoch: 07, Loss: 1.5242, Train: 39.52%, Valid: 27.47% Test: 28.32%\n",
      "Epoch: 08, Loss: 1.4755, Train: 41.00%, Valid: 27.30% Test: 27.37%\n",
      "Epoch: 08, Loss: 1.4755, Train: 41.00%, Valid: 27.30% Test: 27.37%\n",
      "Epoch: 09, Loss: 1.4313, Train: 44.82%, Valid: 38.72% Test: 43.60%\n",
      "Epoch: 09, Loss: 1.4313, Train: 44.82%, Valid: 38.72% Test: 43.60%\n",
      "Epoch: 10, Loss: 1.3931, Train: 47.12%, Valid: 44.74% Test: 49.15%\n",
      "Epoch: 10, Loss: 1.3931, Train: 47.12%, Valid: 44.74% Test: 49.15%\n",
      "Epoch: 11, Loss: 1.3533, Train: 48.29%, Valid: 46.99% Test: 51.13%\n",
      "Epoch: 11, Loss: 1.3533, Train: 48.29%, Valid: 46.99% Test: 51.13%\n",
      "Epoch: 12, Loss: 1.3308, Train: 49.96%, Valid: 48.89% Test: 52.69%\n",
      "Epoch: 12, Loss: 1.3308, Train: 49.96%, Valid: 48.89% Test: 52.69%\n",
      "Epoch: 13, Loss: 1.3067, Train: 51.29%, Valid: 49.67% Test: 53.09%\n",
      "Epoch: 13, Loss: 1.3067, Train: 51.29%, Valid: 49.67% Test: 53.09%\n",
      "Epoch: 14, Loss: 1.2845, Train: 52.32%, Valid: 49.72% Test: 52.75%\n",
      "Epoch: 14, Loss: 1.2845, Train: 52.32%, Valid: 49.72% Test: 52.75%\n",
      "Epoch: 15, Loss: 1.2575, Train: 53.23%, Valid: 50.24% Test: 53.11%\n",
      "Epoch: 15, Loss: 1.2575, Train: 53.23%, Valid: 50.24% Test: 53.11%\n",
      "Epoch: 16, Loss: 1.2434, Train: 54.49%, Valid: 52.09% Test: 54.88%\n",
      "Epoch: 16, Loss: 1.2434, Train: 54.49%, Valid: 52.09% Test: 54.88%\n",
      "Epoch: 17, Loss: 1.2269, Train: 56.20%, Valid: 55.25% Test: 57.91%\n",
      "Epoch: 17, Loss: 1.2269, Train: 56.20%, Valid: 55.25% Test: 57.91%\n",
      "Epoch: 18, Loss: 1.2171, Train: 57.83%, Valid: 58.03% Test: 60.56%\n",
      "Epoch: 18, Loss: 1.2171, Train: 57.83%, Valid: 58.03% Test: 60.56%\n",
      "Epoch: 19, Loss: 1.2034, Train: 59.08%, Valid: 60.05% Test: 62.61%\n",
      "Epoch: 19, Loss: 1.2034, Train: 59.08%, Valid: 60.05% Test: 62.61%\n",
      "Epoch: 20, Loss: 1.1875, Train: 59.78%, Valid: 60.98% Test: 63.47%\n",
      "Epoch: 20, Loss: 1.1875, Train: 59.78%, Valid: 60.98% Test: 63.47%\n",
      "Epoch: 21, Loss: 1.1792, Train: 59.92%, Valid: 60.98% Test: 63.46%\n",
      "Epoch: 21, Loss: 1.1792, Train: 59.92%, Valid: 60.98% Test: 63.46%\n",
      "Epoch: 22, Loss: 1.1727, Train: 60.08%, Valid: 60.92% Test: 63.38%\n",
      "Epoch: 22, Loss: 1.1727, Train: 60.08%, Valid: 60.92% Test: 63.38%\n",
      "Epoch: 23, Loss: 1.1596, Train: 60.42%, Valid: 61.16% Test: 63.46%\n",
      "Epoch: 23, Loss: 1.1596, Train: 60.42%, Valid: 61.16% Test: 63.46%\n",
      "Epoch: 24, Loss: 1.1464, Train: 60.81%, Valid: 61.81% Test: 63.84%\n",
      "Epoch: 24, Loss: 1.1464, Train: 60.81%, Valid: 61.81% Test: 63.84%\n",
      "Epoch: 25, Loss: 1.1433, Train: 61.34%, Valid: 62.52% Test: 64.37%\n",
      "Epoch: 25, Loss: 1.1433, Train: 61.34%, Valid: 62.52% Test: 64.37%\n",
      "Epoch: 26, Loss: 1.1385, Train: 62.25%, Valid: 63.40% Test: 65.09%\n",
      "Epoch: 26, Loss: 1.1385, Train: 62.25%, Valid: 63.40% Test: 65.09%\n",
      "Epoch: 27, Loss: 1.1262, Train: 63.28%, Valid: 64.41% Test: 65.74%\n",
      "Epoch: 27, Loss: 1.1262, Train: 63.28%, Valid: 64.41% Test: 65.74%\n",
      "Epoch: 28, Loss: 1.1210, Train: 64.13%, Valid: 65.03% Test: 65.88%\n",
      "Epoch: 28, Loss: 1.1210, Train: 64.13%, Valid: 65.03% Test: 65.88%\n",
      "Epoch: 29, Loss: 1.1136, Train: 64.67%, Valid: 65.20% Test: 65.83%\n",
      "Epoch: 29, Loss: 1.1136, Train: 64.67%, Valid: 65.20% Test: 65.83%\n",
      "Epoch: 30, Loss: 1.1108, Train: 64.94%, Valid: 65.12% Test: 65.97%\n",
      "Epoch: 30, Loss: 1.1108, Train: 64.94%, Valid: 65.12% Test: 65.97%\n",
      "Epoch: 31, Loss: 1.1010, Train: 65.30%, Valid: 65.22% Test: 66.08%\n",
      "Epoch: 31, Loss: 1.1010, Train: 65.30%, Valid: 65.22% Test: 66.08%\n",
      "Epoch: 32, Loss: 1.0933, Train: 65.97%, Valid: 65.53% Test: 66.02%\n",
      "Epoch: 32, Loss: 1.0933, Train: 65.97%, Valid: 65.53% Test: 66.02%\n",
      "Epoch: 33, Loss: 1.0849, Train: 66.42%, Valid: 65.89% Test: 65.82%\n",
      "Epoch: 33, Loss: 1.0849, Train: 66.42%, Valid: 65.89% Test: 65.82%\n",
      "Epoch: 34, Loss: 1.0840, Train: 66.78%, Valid: 65.94% Test: 65.16%\n",
      "Epoch: 34, Loss: 1.0840, Train: 66.78%, Valid: 65.94% Test: 65.16%\n",
      "Epoch: 35, Loss: 1.0799, Train: 66.94%, Valid: 65.86% Test: 64.62%\n",
      "Epoch: 35, Loss: 1.0799, Train: 66.94%, Valid: 65.86% Test: 64.62%\n",
      "Epoch: 36, Loss: 1.0729, Train: 67.35%, Valid: 66.09% Test: 64.64%\n",
      "Epoch: 36, Loss: 1.0729, Train: 67.35%, Valid: 66.09% Test: 64.64%\n",
      "Epoch: 37, Loss: 1.0689, Train: 67.72%, Valid: 66.70% Test: 65.35%\n",
      "Epoch: 37, Loss: 1.0689, Train: 67.72%, Valid: 66.70% Test: 65.35%\n",
      "Epoch: 38, Loss: 1.0636, Train: 68.23%, Valid: 67.87% Test: 66.80%\n",
      "Epoch: 38, Loss: 1.0636, Train: 68.23%, Valid: 67.87% Test: 66.80%\n",
      "Epoch: 39, Loss: 1.0556, Train: 68.49%, Valid: 68.54% Test: 67.94%\n",
      "Epoch: 39, Loss: 1.0556, Train: 68.49%, Valid: 68.54% Test: 67.94%\n",
      "Epoch: 40, Loss: 1.0510, Train: 68.61%, Valid: 68.77% Test: 68.59%\n",
      "Epoch: 40, Loss: 1.0510, Train: 68.61%, Valid: 68.77% Test: 68.59%\n",
      "Epoch: 41, Loss: 1.0493, Train: 68.65%, Valid: 68.90% Test: 68.82%\n",
      "Epoch: 41, Loss: 1.0493, Train: 68.65%, Valid: 68.90% Test: 68.82%\n",
      "Epoch: 42, Loss: 1.0451, Train: 68.81%, Valid: 69.01% Test: 69.07%\n",
      "Epoch: 42, Loss: 1.0451, Train: 68.81%, Valid: 69.01% Test: 69.07%\n",
      "Epoch: 43, Loss: 1.0409, Train: 69.30%, Valid: 69.21% Test: 69.08%\n",
      "Epoch: 43, Loss: 1.0409, Train: 69.30%, Valid: 69.21% Test: 69.08%\n",
      "Epoch: 44, Loss: 1.0345, Train: 69.74%, Valid: 69.35% Test: 69.12%\n",
      "Epoch: 44, Loss: 1.0345, Train: 69.74%, Valid: 69.35% Test: 69.12%\n",
      "Epoch: 45, Loss: 1.0364, Train: 70.08%, Valid: 69.55% Test: 69.21%\n",
      "Epoch: 45, Loss: 1.0364, Train: 70.08%, Valid: 69.55% Test: 69.21%\n",
      "Epoch: 46, Loss: 1.0313, Train: 70.39%, Valid: 69.80% Test: 69.20%\n",
      "Epoch: 46, Loss: 1.0313, Train: 70.39%, Valid: 69.80% Test: 69.20%\n",
      "Epoch: 47, Loss: 1.0252, Train: 70.56%, Valid: 69.82% Test: 69.15%\n",
      "Epoch: 47, Loss: 1.0252, Train: 70.56%, Valid: 69.82% Test: 69.15%\n",
      "Epoch: 48, Loss: 1.0216, Train: 70.75%, Valid: 69.91% Test: 69.16%\n",
      "Epoch: 48, Loss: 1.0216, Train: 70.75%, Valid: 69.91% Test: 69.16%\n",
      "Epoch: 49, Loss: 1.0184, Train: 70.94%, Valid: 69.99% Test: 69.20%\n",
      "Epoch: 49, Loss: 1.0184, Train: 70.94%, Valid: 69.99% Test: 69.20%\n",
      "Epoch: 50, Loss: 1.0183, Train: 71.15%, Valid: 70.18% Test: 69.26%\n",
      "Epoch: 50, Loss: 1.0183, Train: 71.15%, Valid: 70.18% Test: 69.26%\n",
      "Epoch: 51, Loss: 1.0096, Train: 71.11%, Valid: 70.22% Test: 69.37%\n",
      "Epoch: 51, Loss: 1.0096, Train: 71.11%, Valid: 70.22% Test: 69.37%\n",
      "Epoch: 52, Loss: 1.0094, Train: 71.16%, Valid: 70.28% Test: 69.56%\n",
      "Epoch: 52, Loss: 1.0094, Train: 71.16%, Valid: 70.28% Test: 69.56%\n",
      "Epoch: 53, Loss: 1.0054, Train: 71.26%, Valid: 70.41% Test: 69.56%\n",
      "Epoch: 53, Loss: 1.0054, Train: 71.26%, Valid: 70.41% Test: 69.56%\n",
      "Epoch: 54, Loss: 1.0044, Train: 71.41%, Valid: 70.41% Test: 69.45%\n",
      "Epoch: 54, Loss: 1.0044, Train: 71.41%, Valid: 70.41% Test: 69.45%\n",
      "Epoch: 55, Loss: 1.0009, Train: 71.54%, Valid: 70.28% Test: 69.19%\n",
      "Epoch: 55, Loss: 1.0009, Train: 71.54%, Valid: 70.28% Test: 69.19%\n",
      "Epoch: 56, Loss: 0.9989, Train: 71.59%, Valid: 70.48% Test: 69.42%\n",
      "Epoch: 56, Loss: 0.9989, Train: 71.59%, Valid: 70.48% Test: 69.42%\n",
      "Epoch: 57, Loss: 0.9951, Train: 71.59%, Valid: 70.57% Test: 70.02%\n",
      "Epoch: 57, Loss: 0.9951, Train: 71.59%, Valid: 70.57% Test: 70.02%\n",
      "Epoch: 58, Loss: 0.9923, Train: 71.57%, Valid: 70.55% Test: 70.25%\n",
      "Epoch: 58, Loss: 0.9923, Train: 71.57%, Valid: 70.55% Test: 70.25%\n",
      "Epoch: 59, Loss: 0.9891, Train: 71.67%, Valid: 70.56% Test: 70.10%\n",
      "Epoch: 59, Loss: 0.9891, Train: 71.67%, Valid: 70.56% Test: 70.10%\n",
      "Epoch: 60, Loss: 0.9867, Train: 71.86%, Valid: 70.55% Test: 69.63%\n",
      "Epoch: 60, Loss: 0.9867, Train: 71.86%, Valid: 70.55% Test: 69.63%\n",
      "Epoch: 61, Loss: 0.9855, Train: 71.81%, Valid: 70.61% Test: 69.33%\n",
      "Epoch: 61, Loss: 0.9855, Train: 71.81%, Valid: 70.61% Test: 69.33%\n",
      "Epoch: 62, Loss: 0.9824, Train: 71.92%, Valid: 70.69% Test: 69.30%\n",
      "Epoch: 62, Loss: 0.9824, Train: 71.92%, Valid: 70.69% Test: 69.30%\n",
      "Epoch: 63, Loss: 0.9803, Train: 71.98%, Valid: 70.65% Test: 69.18%\n",
      "Epoch: 63, Loss: 0.9803, Train: 71.98%, Valid: 70.65% Test: 69.18%\n",
      "Epoch: 64, Loss: 0.9769, Train: 71.90%, Valid: 70.47% Test: 68.94%\n",
      "Epoch: 64, Loss: 0.9769, Train: 71.90%, Valid: 70.47% Test: 68.94%\n",
      "Epoch: 65, Loss: 0.9772, Train: 71.95%, Valid: 70.32% Test: 68.72%\n",
      "Epoch: 65, Loss: 0.9772, Train: 71.95%, Valid: 70.32% Test: 68.72%\n",
      "Epoch: 66, Loss: 0.9761, Train: 71.98%, Valid: 70.02% Test: 68.14%\n",
      "Epoch: 66, Loss: 0.9761, Train: 71.98%, Valid: 70.02% Test: 68.14%\n",
      "Epoch: 67, Loss: 0.9724, Train: 72.19%, Valid: 70.52% Test: 68.90%\n",
      "Epoch: 67, Loss: 0.9724, Train: 72.19%, Valid: 70.52% Test: 68.90%\n",
      "Epoch: 68, Loss: 0.9691, Train: 72.40%, Valid: 70.93% Test: 69.61%\n",
      "Epoch: 68, Loss: 0.9691, Train: 72.40%, Valid: 70.93% Test: 69.61%\n",
      "Epoch: 69, Loss: 0.9677, Train: 72.47%, Valid: 70.99% Test: 69.75%\n",
      "Epoch: 69, Loss: 0.9677, Train: 72.47%, Valid: 70.99% Test: 69.75%\n",
      "Epoch: 70, Loss: 0.9628, Train: 72.46%, Valid: 70.47% Test: 68.88%\n",
      "Epoch: 70, Loss: 0.9628, Train: 72.46%, Valid: 70.47% Test: 68.88%\n",
      "Epoch: 71, Loss: 0.9620, Train: 72.48%, Valid: 70.25% Test: 68.59%\n",
      "Epoch: 71, Loss: 0.9620, Train: 72.48%, Valid: 70.25% Test: 68.59%\n",
      "Epoch: 72, Loss: 0.9628, Train: 72.55%, Valid: 70.47% Test: 68.93%\n",
      "Epoch: 72, Loss: 0.9628, Train: 72.55%, Valid: 70.47% Test: 68.93%\n",
      "Epoch: 73, Loss: 0.9603, Train: 72.50%, Valid: 71.04% Test: 70.17%\n",
      "Epoch: 73, Loss: 0.9603, Train: 72.50%, Valid: 71.04% Test: 70.17%\n",
      "Epoch: 74, Loss: 0.9553, Train: 72.44%, Valid: 71.32% Test: 70.63%\n",
      "Epoch: 74, Loss: 0.9553, Train: 72.44%, Valid: 71.32% Test: 70.63%\n",
      "Epoch: 75, Loss: 0.9576, Train: 72.70%, Valid: 71.42% Test: 70.78%\n",
      "Epoch: 75, Loss: 0.9576, Train: 72.70%, Valid: 71.42% Test: 70.78%\n",
      "Epoch: 76, Loss: 0.9560, Train: 72.84%, Valid: 71.61% Test: 70.79%\n",
      "Epoch: 76, Loss: 0.9560, Train: 72.84%, Valid: 71.61% Test: 70.79%\n",
      "Epoch: 77, Loss: 0.9490, Train: 72.80%, Valid: 71.39% Test: 71.06%\n",
      "Epoch: 77, Loss: 0.9490, Train: 72.80%, Valid: 71.39% Test: 71.06%\n",
      "Epoch: 78, Loss: 0.9520, Train: 72.73%, Valid: 70.81% Test: 69.92%\n",
      "Epoch: 78, Loss: 0.9520, Train: 72.73%, Valid: 70.81% Test: 69.92%\n",
      "Epoch: 79, Loss: 0.9474, Train: 72.64%, Valid: 70.65% Test: 68.91%\n",
      "Epoch: 79, Loss: 0.9474, Train: 72.64%, Valid: 70.65% Test: 68.91%\n",
      "Epoch: 80, Loss: 0.9462, Train: 72.98%, Valid: 71.15% Test: 69.48%\n",
      "Epoch: 80, Loss: 0.9462, Train: 72.98%, Valid: 71.15% Test: 69.48%\n",
      "Epoch: 81, Loss: 0.9457, Train: 72.96%, Valid: 71.37% Test: 70.08%\n",
      "Epoch: 81, Loss: 0.9457, Train: 72.96%, Valid: 71.37% Test: 70.08%\n",
      "Epoch: 82, Loss: 0.9427, Train: 72.87%, Valid: 71.10% Test: 70.07%\n",
      "Epoch: 82, Loss: 0.9427, Train: 72.87%, Valid: 71.10% Test: 70.07%\n",
      "Epoch: 83, Loss: 0.9410, Train: 72.86%, Valid: 70.94% Test: 69.79%\n",
      "Epoch: 83, Loss: 0.9410, Train: 72.86%, Valid: 70.94% Test: 69.79%\n",
      "Epoch: 84, Loss: 0.9400, Train: 72.86%, Valid: 70.67% Test: 69.17%\n",
      "Epoch: 84, Loss: 0.9400, Train: 72.86%, Valid: 70.67% Test: 69.17%\n",
      "Epoch: 85, Loss: 0.9368, Train: 72.83%, Valid: 70.50% Test: 68.64%\n",
      "Epoch: 85, Loss: 0.9368, Train: 72.83%, Valid: 70.50% Test: 68.64%\n",
      "Epoch: 86, Loss: 0.9345, Train: 72.98%, Valid: 70.91% Test: 69.37%\n",
      "Epoch: 86, Loss: 0.9345, Train: 72.98%, Valid: 70.91% Test: 69.37%\n",
      "Epoch: 87, Loss: 0.9359, Train: 73.13%, Valid: 71.52% Test: 70.49%\n",
      "Epoch: 87, Loss: 0.9359, Train: 73.13%, Valid: 71.52% Test: 70.49%\n",
      "Epoch: 88, Loss: 0.9333, Train: 73.21%, Valid: 71.45% Test: 70.50%\n",
      "Epoch: 88, Loss: 0.9333, Train: 73.21%, Valid: 71.45% Test: 70.50%\n",
      "Epoch: 89, Loss: 0.9306, Train: 73.28%, Valid: 71.32% Test: 69.88%\n",
      "Epoch: 89, Loss: 0.9306, Train: 73.28%, Valid: 71.32% Test: 69.88%\n",
      "Epoch: 90, Loss: 0.9285, Train: 73.49%, Valid: 71.42% Test: 70.03%\n",
      "Epoch: 90, Loss: 0.9285, Train: 73.49%, Valid: 71.42% Test: 70.03%\n",
      "Epoch: 91, Loss: 0.9268, Train: 73.55%, Valid: 71.54% Test: 70.32%\n",
      "Epoch: 91, Loss: 0.9268, Train: 73.55%, Valid: 71.54% Test: 70.32%\n",
      "Epoch: 92, Loss: 0.9260, Train: 73.55%, Valid: 71.51% Test: 70.41%\n",
      "Epoch: 92, Loss: 0.9260, Train: 73.55%, Valid: 71.51% Test: 70.41%\n",
      "Epoch: 93, Loss: 0.9234, Train: 73.46%, Valid: 71.22% Test: 69.80%\n",
      "Epoch: 93, Loss: 0.9234, Train: 73.46%, Valid: 71.22% Test: 69.80%\n",
      "Epoch: 94, Loss: 0.9223, Train: 73.49%, Valid: 71.29% Test: 69.84%\n",
      "Epoch: 94, Loss: 0.9223, Train: 73.49%, Valid: 71.29% Test: 69.84%\n",
      "Epoch: 95, Loss: 0.9222, Train: 73.62%, Valid: 71.70% Test: 70.52%\n",
      "Epoch: 95, Loss: 0.9222, Train: 73.62%, Valid: 71.70% Test: 70.52%\n",
      "Epoch: 96, Loss: 0.9182, Train: 73.65%, Valid: 71.73% Test: 70.49%\n",
      "Epoch: 96, Loss: 0.9182, Train: 73.65%, Valid: 71.73% Test: 70.49%\n",
      "Epoch: 97, Loss: 0.9195, Train: 73.56%, Valid: 71.49% Test: 70.39%\n",
      "Epoch: 97, Loss: 0.9195, Train: 73.56%, Valid: 71.49% Test: 70.39%\n",
      "Epoch: 98, Loss: 0.9169, Train: 73.68%, Valid: 71.37% Test: 69.80%\n",
      "Epoch: 98, Loss: 0.9169, Train: 73.68%, Valid: 71.37% Test: 69.80%\n",
      "Epoch: 99, Loss: 0.9158, Train: 73.72%, Valid: 71.45% Test: 70.02%\n",
      "Epoch: 99, Loss: 0.9158, Train: 73.72%, Valid: 71.45% Test: 70.02%\n",
      "Epoch: 100, Loss: 0.9135, Train: 73.74%, Valid: 71.62% Test: 70.58%\n",
      "Epoch: 100, Loss: 0.9135, Train: 73.74%, Valid: 71.62% Test: 70.58%\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "# reset the parameters to initial random value\n",
    "model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "loss_fn = F.nll_loss\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "    loss = train(model, data, train_idx, optimizer, loss_fn)\n",
    "    result = test(model, data, split_idx, evaluator)\n",
    "    train_acc, valid_acc, test_acc = result\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "          f'Loss: {loss:.4f}, '\n",
    "          f'Train: {100 * train_acc:.2f}%, '\n",
    "          f'Valid: {100 * valid_acc:.2f}% '\n",
    "          f'Test: {100 * test_acc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
