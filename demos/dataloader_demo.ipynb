{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5bed62",
   "metadata": {},
   "source": [
    "# What to do:\n",
    "1. download scenario data\n",
    "2. convert everything to graphs - PyG's Data or HeteroData objects, (do it on local computer), this includes:\n",
    "    - setting feature matrix (```Data['nodeType'].x```) which holds feature vectors for all nodes\n",
    "    - setting ```Data['startingNode', 'relation', 'endNode'].edge_index``` matrix of shape [2, num_edges], that holds connections of given edge type\n",
    "    - put the graph (Data or HeteroData) onto GPU:\n",
    "        - ```data = data.pin_memory()```\n",
    "        - ```data = data.to('cuda:0', non_blocking=True)```\n",
    "3. create Dataset from graphs:\n",
    "    - we want dataset that will enable lazy loading (so that we don't store everything in RAM at once, but load one snapshot at a time) and clean iteration\n",
    "    - implement your dataset ```LazyTemporalDataset```, which receives a list of filepaths to tensors (.pt), saved beforehand using ```torch.save(my_tensor_data, 'filename.pt)```\n",
    "    - it has generator interface (it holds state, so that it can yield one item and then next time next item), uses:\n",
    "        - ```yield self[idx]```, which lazily yields one snapshot graph tuple (uses ```torch.load(filename.pt, ...)```)\n",
    "        - we use this like iterator to get next samples lazily\n",
    "4. put it into DataLoader that makes minibatches and handles GPU transfer:\n",
    "    - ```dataloader = DataLoader(dataset, batch_size=4, shuffle=True, pin_memory=True)```\n",
    "5. use dataloader in training loop:\n",
    "    - ```for batch in dataloader:```\n",
    "        - ```batch = batch.to('cuda:0', non_blocking=True)```\n",
    "        - ```out = model(batch.x, batch.edge_index)```\n",
    "\n",
    "Useful links:\n",
    "\n",
    "HeteroData: https://pytorch-geometric.readthedocs.io/en/2.5.0/generated/torch_geometric.data.HeteroData.html#torch_geometric.data.HeteroData\n",
    "\n",
    "Dataset: https://pytorch-geometric.readthedocs.io/en/2.5.0/generated/torch_geometric.data.Dataset.html#torch_geometric.data.Dataset\n",
    "\n",
    "DataLoader: https://pytorch-geometric.readthedocs.io/en/2.5.0/modules/loader.html#torch_geometric.loader.DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b66da5a",
   "metadata": {},
   "source": [
    "### Heterogeneous Graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8487476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2263, -0.1631, -0.3624],\n",
      "        [-0.7786, -0.8193,  1.4414],\n",
      "        [ 0.4437,  0.6856,  1.5653],\n",
      "        [-0.8561, -0.6644,  0.2692],\n",
      "        [ 1.7984, -0.4106,  0.2282],\n",
      "        [ 0.8712,  2.4511,  0.1243],\n",
      "        [-0.8279,  1.3517, -0.1583],\n",
      "        [-0.3681,  0.4416, -0.9410],\n",
      "        [-2.1176,  0.8650, -1.3122],\n",
      "        [-1.0826,  1.3534,  0.0815]]) torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "data = HeteroData()     # PyG's object representing a heterogeneous graph (multiple node and/or edge types)\n",
    "\n",
    "# node types (assigning features to them):\n",
    "num_cars = 10\n",
    "num_car_features = 3\n",
    "data['car'].x = torch.randn(num_cars, num_car_features)\n",
    "num_pedestrians = 10\n",
    "num_pedestrian_features = 3\n",
    "data['pedestrian'].x = torch.tensor([[ 0.2263, -0.1631, -0.3624],\n",
    "                                    [-0.7786, -0.8193,  1.4414],\n",
    "                                    [ 0.4437,  0.6856,  1.5653],\n",
    "                                    [-0.8561, -0.6644,  0.2692],\n",
    "                                    [ 1.7984, -0.4106,  0.2282],\n",
    "                                    [ 0.8712,  2.4511,  0.1243],\n",
    "                                    [-0.8279,  1.3517, -0.1583],\n",
    "                                    [-0.3681,  0.4416, -0.9410],\n",
    "                                    [-2.1176,  0.8650, -1.3122],\n",
    "                                    [-1.0826,  1.3534,  0.0815]])\n",
    "print(data['pedestrian'].x, data['pedestrian'].x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad95b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge types:\n",
    "# edge type (author, writes, paper):\n",
    "data['author', 'writes', 'paper'].edge_index = ...  # [2, num_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe59e5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# PyTorch tensor functionality:\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    data = data.pin_memory()\n",
    "    device = 'cuda'\n",
    "data = data.to(device, non_blocking=True)\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83eb08",
   "metadata": {},
   "source": [
    "### Saving graphs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ce55b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data, 'graph.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb11db0",
   "metadata": {},
   "source": [
    "### Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ac47e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, InMemoryDataset, Dataset\n",
    "\n",
    "# suppose we have three graphs and want to create a dataset out of them:\n",
    "g1 = Data(x=torch.randn(3, 2), edge_index=torch.tensor([[0,1,2],[1,2,0]]))\n",
    "g2 = Data(x=torch.randn(4, 2), edge_index=torch.tensor([[0,1,2,3],[1,2,3,0]]))\n",
    "g3 = Data(x=torch.randn(5, 2), edge_index=torch.tensor([[0,1,2,3,4],[1,2,3,4,0]]))\n",
    "\n",
    "# use InMemoryDataset:\n",
    "class MyGraphDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list):\n",
    "        super().__init__(\".\")\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.num_graphs\n",
    "    \n",
    "\n",
    "# create the dataset:\n",
    "dataset = MyGraphDataset([g1,g2,g3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883e308",
   "metadata": {},
   "source": [
    "NOTE: ```InMemoryDataset``` base class loads EVERYTHING into memory at once by collecting all the Data objects into a single big tensor (with slice indices so PyG knows how to split them back out).\n",
    "\n",
    "If you have limited memory, then use ```Dataset``` base class.\n",
    "\n",
    "Or even better for our purpose, we can use the ```TemporalDataset``` class, which handles dataset in a way to use lazy loading (one graph snapshot at a time), optional preprocessing and clean iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1834e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyTemporalDataset:\n",
    "    def __init__(self, snapshot_paths):\n",
    "        \"\"\"snapshot_paths is a list of filepaths\n",
    "           \n",
    "            (node_features, edge_index, edge_weight, targets_y)\"\"\"\n",
    "        self.snapshot_paths = snapshot_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.snapshot_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        snapshot_path_string = self.snapshot_paths[idx]\n",
    "        data = torch.load(snapshot_path_string, map_location=torch.device(device), \n",
    "                          weights_only=False)    # loads tensors to the device\n",
    "        \n",
    "        # Handle both HeteroData and dict formats\n",
    "        if isinstance(data, dict):\n",
    "            x = data['x']\n",
    "            edge_index = data['edge_index']\n",
    "            edge_weight = data.get('edge_weight')\n",
    "            y = data.get('y')\n",
    "            return (x, edge_index, edge_weight, y)\n",
    "        else:\n",
    "            # Assume it's a PyG Data or HeteroData object\n",
    "            return data\n",
    "\n",
    "    def snapshots(self):    # generator interface\n",
    "        for idx in range(len(self)):\n",
    "            yield self[idx]     # self[idx] triggers __getitem__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d896a",
   "metadata": {},
   "source": [
    "How does ```yield``` work?\n",
    "- when it is executed, python suspends (pauses) the function and hands control back to the caller\n",
    "- caller then has to call ```next(theGeneratorObject)```, then python will resume exactly after the last yield (note: for loop calls ```next(theGeneratorObject)``` by itself)\n",
    "\n",
    "Why does ```self[idx]``` trigger ```self.__getitem__(key)```?\n",
    "- the first is just syntactic sugar for the latter\n",
    "- the special methods in python have names like ```__method__(...)```\n",
    "    - they are hooks, which the interpreter calls automatically for certain operations, examples:\n",
    "        - ```__init__``` is called on instance creation (constructor)\n",
    "        - ```__str__``` is called by ```str()``` or ```print()``` (to string)\n",
    "        - ```__getitem__``` is called by ```obj[key]``` (indexing using [])\n",
    "    - they can be overriden/implemented (not necessarily pre-implemented) to enable the operations (the printout, the subscription using [], ...)\n",
    "    - not all classes must have them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0471ca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PyG object: <class 'torch_geometric.data.hetero_data.HeteroData'>\n",
      "Node types: ['car', 'pedestrian']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gen = dataset.snapshots()\\nfirst_snapshot = next(gen)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# USAGE:\n",
    "snapshot_paths = [\"graph.pt\"]  # saved tensors \"\"\"snap0.pt\", \"snap1.pt\", \"snap2.pt\"\"\"\n",
    "dataset = LazyTemporalDataset(snapshot_paths)\n",
    "\n",
    "# direct iteration:\n",
    "for data in dataset.snapshots():\n",
    "    # Handle both tuple and PyG object formats\n",
    "    if isinstance(data, tuple):\n",
    "        x, edge_index, edge_weight, y = data\n",
    "        print(x.shape, edge_index.shape, y)\n",
    "    else:\n",
    "        # PyG Data or HeteroData object\n",
    "        print(f\"Loaded PyG object: {type(data)}\")\n",
    "        print(f\"Node types: {data.node_types if hasattr(data, 'node_types') else 'N/A'}\")\n",
    "\n",
    "# separate iteration:\n",
    "\"\"\"gen = dataset.snapshots()\n",
    "first_snapshot = next(gen)\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1976417",
   "metadata": {},
   "source": [
    "### Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "131c1ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroDataBatch(\n",
      "  car={\n",
      "    x=[10, 3],\n",
      "    batch=[10],\n",
      "    ptr=[2],\n",
      "  },\n",
      "  pedestrian={\n",
      "    x=[10, 3],\n",
      "    batch=[10],\n",
      "    ptr=[2],\n",
      "  },\n",
      "  (author, writes, paper)={ edge_index=[1] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waymo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
