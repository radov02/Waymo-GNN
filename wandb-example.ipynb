{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "801b9a94",
   "metadata": {},
   "source": [
    "# Waymo Open Motion Dataset - Trajectory Prediction with PyTorch Geometric\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Loading Waymo Open Motion Dataset scenarios from TFRecord files\n",
    "- Converting scenarios to PyTorch Geometric graphs\n",
    "- Training a GCN model for trajectory prediction\n",
    "- Using Weights & Biases for experiment tracking\n",
    "\n",
    "**Note:** This notebook uses individual graph processing (no batching) for compatibility with temporal GNN architectures like EvolveGCN-H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c513fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Packages installed\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.4.0+cu118.html -q\n",
    "!pip install wandb tensorflow protobuf==3.20.3 -q\n",
    "print(\"✓ Packages installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19ce5bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\radov\\.conda\\envs\\waymo\\lib\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "c:\\Users\\radov\\.conda\\envs\\waymo\\lib\\site-packages\\torch_geometric\\typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(\n",
      "c:\\Users\\radov\\.conda\\envs\\waymo\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "c:\\Users\\radov\\.conda\\envs\\waymo\\lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "c:\\Users\\radov\\.conda\\envs\\waymo\\lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\radov\\.conda\\envs\\waymo\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "PyTorch version: 2.4.0+cu118\n",
      "TensorFlow version: 2.15.0\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import wandb\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Add Waymo module path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "from waymo_open_dataset.protos import scenario_pb2\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827324c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mradovicevic-erik1\u001b[0m (\u001b[33mradovicevic-erik1-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will prompt you for your W&B API key.\n",
    "# You can also set the WANDB_API_KEY environment variable.\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6891a",
   "metadata": {},
   "source": [
    "## Download Waymo Open Motion Dataset\n",
    "\n",
    "You can download scenario files from: https://console.cloud.google.com/storage/browser/waymo_open_dataset_motion_v_1_3_0/uncompressed/scenario\n",
    "\n",
    "**Option 1: Using gsutil (recommended)**\n",
    "```bash\n",
    "# Install gcloud SDK first, then:\n",
    "gsutil -m cp gs://waymo_open_dataset_motion_v_1_3_0/uncompressed/scenario/training/uncompressed_scenario_training_training.tfrecord-00000-of-01000 ./data/scenario/training/\n",
    "```\n",
    "\n",
    "**Option 2: Manual download**\n",
    "- Navigate to the GCS browser link above\n",
    "- Download files to `./data/scenario/training/` directory\n",
    "\n",
    "For this example, we'll use files you've already downloaded in the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b728f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# Helper functions to convert Waymo scenarios to PyTorch Geometric graphs\n",
    "\n",
    "def parse_scenario_file(file_path):\n",
    "    \"\"\"Parse a Waymo TFRecord file and return list of scenarios.\"\"\"\n",
    "    dataset = tf.data.TFRecordDataset(file_path, compression_type='')\n",
    "    scenarios = []\n",
    "    for raw_record in dataset:\n",
    "        try:\n",
    "            scenario = scenario_pb2.Scenario.FromString(raw_record.numpy())\n",
    "            scenarios.append(scenario)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing scenario: {e}\")\n",
    "            break\n",
    "    return scenarios\n",
    "\n",
    "def initial_feature_vector(agent, state_index):\n",
    "    \"\"\"Create feature vector for an agent at a specific timestep.\"\"\"\n",
    "    state = agent.states[state_index]\n",
    "    \n",
    "    # Basic features: position, velocity, valid flag\n",
    "    properties = [\n",
    "        state.center_x, \n",
    "        state.center_y, \n",
    "        state.velocity_x, \n",
    "        state.velocity_y, \n",
    "        float(state.valid)\n",
    "    ]\n",
    "    \n",
    "    # One-hot encoding for object type\n",
    "    object_types = {1: 'Vehicle', 2: 'Pedestrian', 3: 'Cyclist', 4: 'Other'}\n",
    "    type_onehot = [\n",
    "        1 if agent.object_type == 1 else 0,  # Vehicle\n",
    "        1 if agent.object_type == 2 else 0,  # Pedestrian\n",
    "        1 if agent.object_type == 3 else 0,  # Cyclist\n",
    "        1 if agent.object_type == 4 else 0   # Other\n",
    "    ]\n",
    "    \n",
    "    return torch.tensor(properties + type_onehot, dtype=torch.float32)\n",
    "\n",
    "def build_edge_index_radius(positions, radius=30.0, valid_mask=None):\n",
    "    \"\"\"Build graph edges based on spatial proximity.\"\"\"\n",
    "    pairwise_distances = torch.cdist(positions, positions)\n",
    "    \n",
    "    if valid_mask is not None:\n",
    "        vm = torch.as_tensor(valid_mask, dtype=torch.bool)\n",
    "        valid_pair = vm[:, None] & vm[None, :]\n",
    "        pairwise_distances = pairwise_distances.clone()\n",
    "        pairwise_distances[~valid_pair] = float('inf')\n",
    "    \n",
    "    # Remove self-loops\n",
    "    pairwise_distances.fill_diagonal_(float('inf'))\n",
    "    \n",
    "    # Create edges for agents within radius\n",
    "    edges_mask = pairwise_distances <= radius\n",
    "    src, dst = torch.where(edges_mask)\n",
    "    edge_index = torch.stack([src, dst], dim=0)\n",
    "    \n",
    "    return edge_index\n",
    "\n",
    "def scenario_to_graph(scenario, timestep, radius=30.0, future_steps=1):\n",
    "    \"\"\"Convert a Waymo scenario at a specific timestep to PyG Data.\"\"\"\n",
    "    node_features = []\n",
    "    positions = []\n",
    "    agent_ids = []\n",
    "    valid_mask = []\n",
    "    \n",
    "    # Extract features for all valid agents at this timestep\n",
    "    for agent in scenario.tracks:\n",
    "        if timestep >= len(agent.states):\n",
    "            continue\n",
    "            \n",
    "        state = agent.states[timestep]\n",
    "        if not state.valid:\n",
    "            continue\n",
    "        \n",
    "        node_features.append(initial_feature_vector(agent, timestep))\n",
    "        positions.append([state.center_x, state.center_y])\n",
    "        agent_ids.append(agent.id)\n",
    "        valid_mask.append(1)\n",
    "    \n",
    "    if len(node_features) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Stack features and positions\n",
    "    x = torch.stack(node_features)\n",
    "    pos = torch.tensor(positions, dtype=torch.float32)\n",
    "    \n",
    "    # Build edges based on proximity\n",
    "    edge_index = build_edge_index_radius(pos, radius, valid_mask)\n",
    "    \n",
    "    # Create labels: future positions (offsets from current position)\n",
    "    labels = []\n",
    "    id_to_agent = {t.id: t for t in scenario.tracks}\n",
    "    for i, agent_id in enumerate(agent_ids):\n",
    "        agent = id_to_agent[agent_id]\n",
    "        future_pos = []\n",
    "        for t in range(1, future_steps + 1):\n",
    "            future_t = timestep + t\n",
    "            if future_t < len(agent.states) and agent.states[future_t].valid:\n",
    "                future_pos.append([\n",
    "                    agent.states[future_t].center_x,\n",
    "                    agent.states[future_t].center_y\n",
    "                ])\n",
    "            else:\n",
    "                # Pad with last known position\n",
    "                last = agent.states[min(future_t, len(agent.states) - 1)]\n",
    "                future_pos.append([last.center_x, last.center_y])\n",
    "        \n",
    "        # Convert to offsets from current position\n",
    "        current_pos = torch.tensor(positions[i], dtype=torch.float32)\n",
    "        future_tensor = torch.tensor(future_pos, dtype=torch.float32)\n",
    "        offsets = future_tensor - current_pos\n",
    "        labels.append(offsets.flatten())\n",
    "    \n",
    "    y = torch.stack(labels)\n",
    "    \n",
    "    # Create PyG Data object\n",
    "    data = Data(x=x, edge_index=edge_index, pos=pos, y=y)\n",
    "    data.agent_ids = agent_ids\n",
    "    data.scenario_id = scenario.scenario_id\n",
    "    \n",
    "    return data\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c2becae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'learning_rate': 0.001, 'epochs': 50, 'hidden_channels': 64, 'dropout': 0.3, 'dataset': 'Waymo Open Motion Dataset', 'architecture': 'GCN', 'radius': 30.0, 'future_steps': 8, 'timestep': 10, 'batch_size': 32, 'num_scenarios': 10}\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters for Waymo dataset\n",
    "config = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 50,\n",
    "    \"hidden_channels\": 64,\n",
    "    \"dropout\": 0.3,\n",
    "    \"dataset\": \"Waymo Open Motion Dataset\",\n",
    "    \"architecture\": \"GCN\",\n",
    "    \"radius\": 30.0,  # meters - spatial proximity for edges\n",
    "    \"future_steps\": 8,  # predict 8 timesteps (0.8 seconds) into future\n",
    "    \"timestep\": 10,  # use timestep 10 as current observation\n",
    "    \"batch_size\": 32,\n",
    "    \"num_scenarios\": 10  # number of scenarios to load for this demo\n",
    "}\n",
    "\n",
    "print(f\"Configuration: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbee3668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 TFRecord file(s)\n",
      "\n",
      "Loading scenarios from: uncompressed_scenario_testing_testing.tfrecord-00000-of-00150\n",
      "\n",
      "============================================================\n",
      "Dataset: Waymo Open Motion Dataset\n",
      "============================================================\n",
      "Number of scenarios loaded: 10\n",
      "Total scenarios in file: 289\n",
      "\n",
      "First Scenario Analysis:\n",
      "  Scenario ID: 53efd22f9e0bd276\n",
      "  SDC track index: 48\n",
      "  Number of agents/tracks: 49\n",
      "  Number of timesteps: 11\n",
      "  Duration: 1.0s\n",
      "  Number of map features: 175\n",
      "\n",
      "  Agent types:\n",
      "    Vehicle: 34\n",
      "    Pedestrian: 15\n",
      "\n",
      "Converting to PyG graph at timestep 10...\n",
      "\n",
      "Graph structure:\n",
      "  Number of nodes: 29\n",
      "  Number of edges: 240\n",
      "  Node feature dim: 9\n",
      "  Label dim (future trajectory): 16\n",
      "  Average degree: 8.28\n",
      "  Has isolated nodes: False\n",
      "  Has self-loops: False\n",
      "  Is undirected: True\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load Waymo Open Motion Dataset scenarios\n",
    "data_dir = './data/scenario/training'\n",
    "\n",
    "# Get list of TFRecord files\n",
    "tfrecord_files = [\n",
    "    os.path.join(data_dir, f) \n",
    "    for f in os.listdir(data_dir) \n",
    "    if f.endswith('.tfrecord') or f.endswith('.tfrecord-00000-of-00150')\n",
    "]\n",
    "\n",
    "if not tfrecord_files:\n",
    "    print(\"⚠ No TFRecord files found in ./data/scenario/training/\")\n",
    "    print(\"Please download files from:\")\n",
    "    print(\"https://console.cloud.google.com/storage/browser/waymo_open_dataset_motion_v_1_3_0/uncompressed/scenario/training\")\n",
    "else:\n",
    "    print(f\"Found {len(tfrecord_files)} TFRecord file(s)\")\n",
    "    \n",
    "    # Load scenarios from first file\n",
    "    print(f\"\\nLoading scenarios from: {os.path.basename(tfrecord_files[0])}\")\n",
    "    all_scenarios = parse_scenario_file(tfrecord_files[0])\n",
    "    \n",
    "    # Limit to configured number for this demo\n",
    "    scenarios = all_scenarios[:config['num_scenarios']]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Dataset: {config['dataset']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Number of scenarios loaded: {len(scenarios)}\")\n",
    "    print(f\"Total scenarios in file: {len(all_scenarios)}\")\n",
    "    \n",
    "    # Analyze first scenario\n",
    "    if scenarios:\n",
    "        scenario = scenarios[0]\n",
    "        print(f\"\\nFirst Scenario Analysis:\")\n",
    "        print(f\"  Scenario ID: {scenario.scenario_id}\")\n",
    "        print(f\"  SDC track index: {scenario.sdc_track_index}\")\n",
    "        print(f\"  Number of agents/tracks: {len(scenario.tracks)}\")\n",
    "        print(f\"  Number of timesteps: {len(scenario.timestamps_seconds)}\")\n",
    "        print(f\"  Duration: {scenario.timestamps_seconds[-1] - scenario.timestamps_seconds[0]:.1f}s\")\n",
    "        print(f\"  Number of map features: {len(scenario.map_features)}\")\n",
    "        \n",
    "        # Count agents by type\n",
    "        agent_types = {}\n",
    "        type_names = {1: 'Vehicle', 2: 'Pedestrian', 3: 'Cyclist', 4: 'Other'}\n",
    "        for track in scenario.tracks:\n",
    "            type_name = type_names.get(track.object_type, 'Unknown')\n",
    "            agent_types[type_name] = agent_types.get(type_name, 0) + 1\n",
    "        \n",
    "        print(f\"\\n  Agent types:\")\n",
    "        for agent_type, count in agent_types.items():\n",
    "            print(f\"    {agent_type}: {count}\")\n",
    "        \n",
    "        # Convert to graph\n",
    "        print(f\"\\nConverting to PyG graph at timestep {config['timestep']}...\")\n",
    "        graph_data = scenario_to_graph(\n",
    "            scenario, \n",
    "            timestep=config['timestep'],\n",
    "            radius=config['radius'],\n",
    "            future_steps=config['future_steps']\n",
    "        )\n",
    "        \n",
    "        if graph_data:\n",
    "            print(f\"\\nGraph structure:\")\n",
    "            print(f\"  Number of nodes: {graph_data.num_nodes}\")\n",
    "            print(f\"  Number of edges: {graph_data.num_edges}\")\n",
    "            print(f\"  Node feature dim: {graph_data.x.shape[1]}\")\n",
    "            print(f\"  Label dim (future trajectory): {graph_data.y.shape[1]}\")\n",
    "            print(f\"  Average degree: {graph_data.num_edges / graph_data.num_nodes:.2f}\")\n",
    "            print(f\"  Has isolated nodes: {graph_data.has_isolated_nodes()}\")\n",
    "            print(f\"  Has self-loops: {graph_data.has_self_loops()}\")\n",
    "            print(f\"  Is undirected: {graph_data.is_undirected()}\")\n",
    "        else:\n",
    "            print(\"  ⚠ No valid graph at this timestep\")\n",
    "    \n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc39bb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Model architecture:\n",
      "  Input dim: 9\n",
      "  Hidden dim: 64\n",
      "  Output dim: 16\n",
      "  Total parameters: 5,840\n",
      "TrajectoryGCN(\n",
      "  (conv1): GCNConv(9, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 16)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define GCN model for trajectory prediction\n",
    "class TrajectoryGCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_channels, output_dim, dropout=0.3):\n",
    "        super(TrajectoryGCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, output_dim)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # First GCN layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # Second GCN layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # Output layer (trajectory prediction)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if graph_data:\n",
    "    input_dim = graph_data.x.shape[1]\n",
    "    output_dim = graph_data.y.shape[1]  # future_steps * 2 (x,y offsets)\n",
    "    \n",
    "    model = TrajectoryGCN(\n",
    "        input_dim=input_dim,\n",
    "        hidden_channels=config['hidden_channels'],\n",
    "        output_dim=output_dim,\n",
    "        dropout=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"\\nModel architecture:\")\n",
    "    print(f\"  Input dim: {input_dim}\")\n",
    "    print(f\"  Hidden dim: {config['hidden_channels']}\")\n",
    "    print(f\"  Output dim: {output_dim}\")\n",
    "    print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0525c96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\radov\\dev\\waymo-open-dataset\\wandb\\run-20251027_191251-v55pkuyd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/radovicevic-erik1-/waymo-trajectory-prediction/runs/v55pkuyd' target=\"_blank\">GCN_r30.0_h64</a></strong> to <a href='https://wandb.ai/radovicevic-erik1-/waymo-trajectory-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/radovicevic-erik1-/waymo-trajectory-prediction' target=\"_blank\">https://wandb.ai/radovicevic-erik1-/waymo-trajectory-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/radovicevic-erik1-/waymo-trajectory-prediction/runs/v55pkuyd' target=\"_blank\">https://wandb.ai/radovicevic-erik1-/waymo-trajectory-prediction/runs/v55pkuyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ W&B initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize W&B run\n",
    "wandb.init(\n",
    "    project=\"waymo-trajectory-prediction\",\n",
    "    config=config,\n",
    "    name=f\"GCN_r{config['radius']}_h{config['hidden_channels']}\"\n",
    ")\n",
    "\n",
    "# Log model architecture\n",
    "wandb.watch(model, log='all', log_freq=10)\n",
    "\n",
    "print(\"✓ W&B initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c84c4cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training graphs...\n",
      "  Processed 5/10 scenarios\n",
      "  Processed 10/10 scenarios\n",
      "\n",
      "✓ Created 10 training graphs\n",
      "  Average nodes per graph: 32.2\n",
      "  Average edges per graph: 301.4\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data - convert all scenarios to graphs\n",
    "print(\"Preparing training graphs...\")\n",
    "train_graphs = []\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    graph = scenario_to_graph(\n",
    "        scenario,\n",
    "        timestep=config['timestep'],\n",
    "        radius=config['radius'],\n",
    "        future_steps=config['future_steps']\n",
    "    )\n",
    "    if graph is not None:\n",
    "        train_graphs.append(graph)\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"  Processed {i + 1}/{len(scenarios)} scenarios\")\n",
    "\n",
    "print(f\"\\n✓ Created {len(train_graphs)} training graphs\")\n",
    "print(f\"  Average nodes per graph: {sum(g.num_nodes for g in train_graphs) / len(train_graphs):.1f}\")\n",
    "print(f\"  Average edges per graph: {sum(g.num_edges for g in train_graphs) / len(train_graphs):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f3c918b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for 50 epochs...\n",
      "============================================================\n",
      "Epoch   1/50 | Loss: 507660.445410\n",
      "Epoch   5/50 | Loss: 61600.854626\n",
      "Epoch  10/50 | Loss: 41588.555597\n",
      "Epoch  15/50 | Loss: 32595.117230\n",
      "Epoch  20/50 | Loss: 28589.013644\n",
      "Epoch  25/50 | Loss: 22326.270651\n",
      "Epoch  30/50 | Loss: 15802.430869\n",
      "Epoch  35/50 | Loss: 11541.796442\n",
      "Epoch  40/50 | Loss: 11237.283972\n",
      "Epoch  45/50 | Loss: 7226.145450\n",
      "Epoch  50/50 | Loss: 7445.612439\n",
      "============================================================\n",
      "✓ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "print(f\"\\nStarting training for {config['epochs']} epochs...\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Train on each graph\n",
    "    for graph in train_graphs:\n",
    "        graph = graph.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "        \n",
    "        # Compute loss (MSE on trajectory predictions)\n",
    "        loss = criterion(out, graph.y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / len(train_graphs)\n",
    "    \n",
    "    # Log to W&B\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": avg_loss,\n",
    "        \"avg_loss_per_graph\": avg_loss\n",
    "    })\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1:3d}/{config['epochs']} | Loss: {avg_loss:.6f}\")\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e6deb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on sample graph:\n",
      "  Scenario ID: 53efd22f9e0bd276\n",
      "  Number of agents: 29\n",
      "  MSE: 2190.499512\n",
      "  MAE: 37.408176\n",
      "\n",
      "Sample predictions (first 3 agents):\n",
      "\n",
      "  Agent 0 (ID: 259):\n",
      "    Predicted final position offset: (76.16, 34.50)\n",
      "    True final position offset:      (0.00, 0.00)\n",
      "    Error: 83.61 meters\n",
      "\n",
      "  Agent 1 (ID: 260):\n",
      "    Predicted final position offset: (88.52, 40.13)\n",
      "    True final position offset:      (0.00, 0.00)\n",
      "    Error: 97.19 meters\n",
      "\n",
      "  Agent 2 (ID: 261):\n",
      "    Predicted final position offset: (72.68, 32.69)\n",
      "    True final position offset:      (0.00, 0.00)\n",
      "    Error: 79.69 meters\n",
      "\n",
      "✓ Evaluation complete\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on a sample graph\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Take first graph for visualization\n",
    "    sample_graph = train_graphs[0].to(device)\n",
    "    \n",
    "    # Predict trajectories\n",
    "    predictions = model(sample_graph.x, sample_graph.edge_index)\n",
    "    \n",
    "    # Compute metrics\n",
    "    mse = criterion(predictions, sample_graph.y)\n",
    "    mae = torch.nn.L1Loss()(predictions, sample_graph.y)\n",
    "    \n",
    "    print(f\"\\nEvaluation on sample graph:\")\n",
    "    print(f\"  Scenario ID: {sample_graph.scenario_id}\")\n",
    "    print(f\"  Number of agents: {sample_graph.num_nodes}\")\n",
    "    print(f\"  MSE: {mse.item():.6f}\")\n",
    "    print(f\"  MAE: {mae.item():.6f}\")\n",
    "    \n",
    "    # Log final metrics to W&B\n",
    "    wandb.log({\n",
    "        \"final_mse\": mse.item(),\n",
    "        \"final_mae\": mae.item(),\n",
    "        \"num_graphs\": len(train_graphs)\n",
    "    })\n",
    "    \n",
    "    # Show sample predictions\n",
    "    print(f\"\\nSample predictions (first 3 agents):\")\n",
    "    for i in range(min(3, sample_graph.num_nodes)):\n",
    "        pred = predictions[i].cpu().numpy()\n",
    "        true = sample_graph.y[i].cpu().numpy()\n",
    "        \n",
    "        # Reshape to (future_steps, 2)\n",
    "        pred_traj = pred.reshape(-1, 2)\n",
    "        true_traj = true.reshape(-1, 2)\n",
    "        \n",
    "        print(f\"\\n  Agent {i} (ID: {sample_graph.agent_ids[i]}):\")\n",
    "        print(f\"    Predicted final position offset: ({pred_traj[-1, 0]:.2f}, {pred_traj[-1, 1]:.2f})\")\n",
    "        print(f\"    True final position offset:      ({true_traj[-1, 0]:.2f}, {true_traj[-1, 1]:.2f})\")\n",
    "        print(f\"    Error: {np.linalg.norm(pred_traj[-1] - true_traj[-1]):.2f} meters\")\n",
    "\n",
    "print(\"\\n✓ Evaluation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7ff68de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss_per_graph</td><td>█▄▃▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>final_mae</td><td>▁</td></tr><tr><td>final_mse</td><td>▁</td></tr><tr><td>num_graphs</td><td>▁</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss_per_graph</td><td>7445.61244</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>final_mae</td><td>37.40818</td></tr><tr><td>final_mse</td><td>2190.49951</td></tr><tr><td>num_graphs</td><td>10</td></tr><tr><td>train_loss</td><td>7445.61244</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_r30.0_h64</strong> at: <a href='https://wandb.ai/radovicevic-erik1-/waymo-trajectory-prediction/runs/v55pkuyd' target=\"_blank\">https://wandb.ai/radovicevic-erik1-/waymo-trajectory-prediction/runs/v55pkuyd</a><br> View project at: <a href='https://wandb.ai/radovicevic-erik1-/waymo-trajectory-prediction' target=\"_blank\">https://wandb.ai/radovicevic-erik1-/waymo-trajectory-prediction</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251027_191251-v55pkuyd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ W&B run finished\n",
      "\n",
      "View your results at: https://wandb.ai\n"
     ]
    }
   ],
   "source": [
    "# Finish W&B run\n",
    "wandb.finish()\n",
    "\n",
    "print(\"✓ W&B run finished\")\n",
    "print(\"\\nView your results at: https://wandb.ai\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waymo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
